"","title","author","subject","abstract","meta"
"1","Learnability Gaps of Strategic Classification","Lee Cohen, Yishay Mansour, Shay Moran, Han Shao","Machine Learning (cs.LG)","In contrast with standard classification tasks, strategic classification involves agents strategically modifying their features in an effort to receive favorable predictions. For instance, given a classifier determining loan approval based on credit scores, applicants may open or close their credit cards to fool the classifier. The learning goal is to find a classifier robust against strategic manipulations. Various settings, based on what and when information is known, have been explored in strategic classification. In this work, we focus on addressing a fundamental question: the learnability gaps between strategic classification and standard learning. We essentially show that any learnable class is also strategically learnable: we first consider a fully informative setting, where the manipulation structure (which is modeled by a manipulation graph $G^\star$) is known and during training time the learner has access to both the pre-manipulation data and post-manipulation data. We provide nearly tight sample complexity and regret bounds, offering significant improvements over prior results. Then, we relax the fully informative setting by introducing two natural types of uncertainty. First, following Ahmadi et al. (2023), we consider the setting in which the learner only has access to the post-manipulation data. We improve the results of Ahmadi et al. (2023) and close the gap between mistake upper bound and lower bound raised by them. Our second relaxation of the fully informative setting introduces uncertainty to the manipulation structure. That is, we assume that the manipulation graph is unknown but belongs to a known class of graphs. We provide nearly tight bounds on the learning complexity in various unknown manipulation graph settings. Notably, our algorithm in this setting is of independent interest and can be applied to other problems such as multi-label learning.","Thu, 29 Feb 2024 16:09:19 UTC (57 KB)"
"2","Card-Based Overwriting Protocol for Equality Function and Applications","Suthee Ruangwises, Tomoki Ono, Yoshiki Abe, Kyosuke Hatsugai, Mitsugu Iwamoto","Cryptography and Security (cs.CR)","Research in the area of secure multi-party computation with an unconventional method of using a physical deck of playing cards began in 1989 when den Boar proposed a protocol to compute the logical AND function using five cards. Since then, the area has gained interest from many researchers and several card-based protocols to compute various functions have been developed. In this paper, we propose a card-based protocol called the overwriting protocol that can securely compute the $k$-candidate $n$-variable equality function $f: \{0,1,\ldots ,k-1\}^n \rightarrow \{0,1\}$. We also apply the technique used in this protocol to compute other similar functions.","Mon, 26 Feb 2024 04:13:51 UTC (9 KB)"
"3","An Empirical Study of Challenges in Machine Learning Asset Management","Zhimin Zhao, Yihao Chen, Abdul Ali Bangash, Bram Adams, Ahmed E. Hassan","Software Engineering (cs.SE)","In machine learning (ML), efficient asset management, including ML models, datasets, algorithms, and tools, is vital for resource optimization, consistent performance, and a streamlined development lifecycle. This enables quicker iterations, adaptability, reduced development-to-deployment time, and reliable outputs. Despite existing research, a significant knowledge gap remains in operational challenges like model versioning, data traceability, and collaboration, which are crucial for the success of ML projects. Our study aims to address this gap by analyzing 15,065 posts from developer forums and platforms, employing a mixed-method approach to classify inquiries, extract challenges using BERTopic, and identify solutions through open card sorting and BERTopic clustering. We uncover 133 topics related to asset management challenges, grouped into 16 macro-topics, with software dependency, model deployment, and model training being the most discussed. We also find 79 solution topics, categorized under 18 macro-topics, highlighting software dependency, feature development, and file management as key solutions. This research underscores the need for further exploration of identified pain points and the importance of collaborative efforts across academia, industry, and the research community.","Sun, 25 Feb 2024 05:05:52 UTC (2,155 KB)[v2] Wed, 28 Feb 2024 05:58:18 UTC (2,155 KB)"
"4","Differentially Private Fair Binary Classifications","Hrad Ghoukasian, Shahab Asoodeh","Machine Learning (cs.LG)","In this work, we investigate binary classification under the constraints of both differential privacy and fairness. We first propose an algorithm based on the decoupling technique for learning a classifier with only fairness guarantee. This algorithm takes in classifiers trained on different demographic groups and generates a single classifier satisfying statistical parity. We then refine this algorithm to incorporate differential privacy. The performance of the final algorithm is rigorously examined in terms of privacy, fairness, and utility guarantees. Empirical evaluations conducted on the Adult and Credit Card datasets illustrate that our algorithm outperforms the state-of-the-art in terms of fairness guarantees, while maintaining the same level of privacy and utility.","Fri, 23 Feb 2024 20:52:59 UTC (31 KB)"
"5","CaT-GNN: Enhancing Credit Card Fraud Detection via Causal Temporal Graph Neural Networks","Yifan Duan, Guibin Zhang, Shilong Wang, Xiaojiang Peng, Wang Ziqi, Junyuan Mao, Hao Wu, Xinke Jiang, Kun Wang","Machine Learning (cs.LG)","Credit card fraud poses a significant threat to the economy. While Graph Neural Network (GNN)-based fraud detection methods perform well, they often overlook the causal effect of a node's local structure on predictions. This paper introduces a novel method for credit card fraud detection, the \textbf{\underline{Ca}}usal \textbf{\underline{T}}emporal \textbf{\underline{G}}raph \textbf{\underline{N}}eural \textbf{N}etwork (CaT-GNN), which leverages causal invariant learning to reveal inherent correlations within transaction data. By decomposing the problem into discovery and intervention phases, CaT-GNN identifies causal nodes within the transaction graph and applies a causal mixup strategy to enhance the model's robustness and interpretability. CaT-GNN consists of two key components: Causal-Inspector and Causal-Intervener. The Causal-Inspector utilizes attention weights in the temporal attention mechanism to identify causal and environment nodes without introducing additional parameters. Subsequently, the Causal-Intervener performs a causal mixup enhancement on environment nodes based on the set of nodes. Evaluated on three datasets, including a private financial dataset and two public datasets, CaT-GNN demonstrates superior performance over existing state-of-the-art methods. Our findings highlight the potential of integrating causal reasoning with graph neural networks to improve fraud detection capabilities in financial transactions.","Thu, 22 Feb 2024 17:08:09 UTC (630 KB)"
"6","Securing Transactions: A Hybrid Dependable Ensemble Machine Learning Model using IHT-LR and Grid Search","Md. Alamin Talukder, Rakib Hossen, Md Ashraf Uddin, Mohammed Nasir Uddin, Uzzal Kumar Acharjee","Machine Learning (cs.LG)","Financial institutions and businesses face an ongoing challenge from fraudulent transactions, prompting the need for effective detection methods. Detecting credit card fraud is crucial for identifying and preventing unauthorized transactions.Timely detection of fraud enables investigators to take swift actions to mitigate further losses. However, the investigation process is often time-consuming, limiting the number of alerts that can be thoroughly examined each day. Therefore, the primary objective of a fraud detection model is to provide accurate alerts while minimizing false alarms and missed fraud cases. In this paper, we introduce a state-of-the-art hybrid ensemble (ENS) dependable Machine learning (ML) model that intelligently combines multiple algorithms with proper weighted optimization using Grid search, including Decision Tree (DT), Random Forest (RF), K-Nearest Neighbor (KNN), and Multilayer Perceptron (MLP), to enhance fraud identification. To address the data imbalance issue, we employ the Instant Hardness Threshold (IHT) technique in conjunction with Logistic Regression (LR), surpassing conventional approaches. Our experiments are conducted on a publicly available credit card dataset comprising 284,807 transactions. The proposed model achieves impressive accuracy rates of 99.66%, 99.73%, 98.56%, and 99.79%, and a perfect 100% for the DT, RF, KNN, MLP and ENS models, respectively. The hybrid ensemble model outperforms existing works, establishing a new benchmark for detecting fraudulent transactions in high-frequency scenarios. The results highlight the effectiveness and reliability of our approach, demonstrating superior performance metrics and showcasing its exceptional potential for real-world fraud detection applications.","Thu, 22 Feb 2024 09:01:42 UTC (512 KB)"
"7","Model Checking Logical Actions in Magic Tricks","Weijun Zhu","Logic in Computer Science (cs.LO)","Some Magic Tricks (MT), such as many kinds of Card Magic (CM), consisting of human computational or logical actions. How to ensure the logical correctness of these MTs? In this paper, the Model Checking (MC) technique is employed to study a typical CM via a case study. First, computational operations of a CM called shousuigongcishi can be described by a Magic Algorithm (MAR). Second, the logical correctness is portrayed by a temporal logic formula. On the basis of it, this MT logical correctness problem is reduced to the model checking problem. As a result, the Magic Trick Model Checking (MTMC) technique aims to verify whether a designed MT meets its architect's anticipation and requirements, or not, in terms of logic and computations.","Wed, 21 Feb 2024 13:34:15 UTC (362 KB)"
"8","Mask-up: Investigating Biases in Face Re-identification for Masked Faces","Siddharth D Jaiswal, Ankit Kr. Verma, Animesh Mukherjee","Computer Vision and Pattern Recognition (cs.CV)","AI based Face Recognition Systems (FRSs) are now widely distributed and deployed as MLaaS solutions all over the world, moreso since the COVID-19 pandemic for tasks ranging from validating individuals' faces while buying SIM cards to surveillance of citizens. Extensive biases have been reported against marginalized groups in these systems and have led to highly discriminatory outcomes. The post-pandemic world has normalized wearing face masks but FRSs have not kept up with the changing times. As a result, these systems are susceptible to mask based face occlusion. In this study, we audit four commercial and nine open-source FRSs for the task of face re-identification between different varieties of masked and unmasked images across five benchmark datasets (total 14,722 images). These simulate a realistic validation/surveillance task as deployed in all major countries around the world. Three of the commercial and five of the open-source FRSs are highly inaccurate; they further perpetuate biases against non-White individuals, with the lowest accuracy being 0%. A survey for the same task with 85 human participants also results in a low accuracy of 40%. Thus a human-in-the-loop moderation in the pipeline does not alleviate the concerns, as has been frequently hypothesized in literature. Our large-scale study shows that developers, lawmakers and users of such services need to rethink the design principles behind FRSs, especially for the task of face re-identification, taking cognizance of observed biases.","Wed, 21 Feb 2024 12:48:45 UTC (4,016 KB)"
"9","Game Design Inspired by Scientific Concepts of Quantum Physics","Sunanda Prabhu Gaunkar, Nancy Kawalek, Denise Fischer, Umang Bhatia, Shobhit Verma, Filip Rozpedek, Uri Zvi","Popular Physics (physics.pop-ph)","The huge gap between the public perception of science and the reality of scientific research severely limits the scope of public engagement with science. We create and develop new theatre, film and games work and related artistic endeavors inspired by science and technology. In this paper, we describe the Quantum Games Project, one of the most recent artistic endeavors in our lab. This project consists of a series of card and digital games and an immersive experience, all of which expose the public to quantum physics without learning barriers. Quantum physics explains the counter-intuitive and surprising ways matter behaves at the subatomic level. It is an exciting and growing field that offers solutions to new technological problems. However, learning quantum physics requires several prerequisites, such as a foundation in the sciences and mathematics, and is primarily taught at the undergraduate and higher levels. As a result, the concepts may be too elusive and abstract for the general public to learn independently. This difficulty is compounded by the limited availability of easily understandable resources and teaching materials that do not employ scientific jargon and equations. Our work attempts to solve this problem by communicating the concepts of quantum physics in a way that is comprehensible and accessible to the general public. This paper provides a general overview of the development of the Quantum Games Project, focusing specifically on the Quantum Photo Booth experience, and describes how science is integrated into the very nature of the game development process and its outcome.","Tue, 20 Feb 2024 23:53:16 UTC (14,270 KB)"
"10","Vision System Prototype for Inspection and Monitoring with a Smart Camera","Efren Hernández-Molina, Benjamin Ojeda-Magaña, Jose Guadalupe Robledo-Hernández, Ruben Ruelas","Computer Vision and Pattern Recognition (cs.CV)","This paper presents the design of an artificial vision system prototype for automatic inspection and monitoring of objects over a conveyor belt and using a Smart camera 2D BOA-INS. The prototype consists of a conveyor belt and an embedded system based on an Arduino Mega card for system control, and it has as main peripherals the smart camera, a direct current motor, a photoelectric sensor, LED illumination and LEDs indicating the status (good or defect) of each evaluated object. The application of the prototype is for educational purposes, so that undergraduate, master and diploma students can simulate a continuous production line, controlled by an embedded system, and perform quality control by monitoring through a visual system and a personal computer. This allows implementing the topics of embedded systems, artificial vision, artificial intelligence, pattern recognition, automatic control, as well as automation of real processes.","Tue, 20 Feb 2024 18:58:23 UTC (2,077 KB)"
"11","GTBench: Uncovering the Strategic Reasoning Limitations of LLMs via Game-Theoretic Evaluations","Jinhao Duan, Renming Zhang, James Diffenderfer, Bhavya Kailkhura, Lichao Sun, Elias Stengel-Eskin, Mohit Bansal, Tianlong Chen, Kaidi Xu","Computation and Language (cs.CL)","As Large Language Models (LLMs) are integrated into critical real-world applications, their strategic and logical reasoning abilities are increasingly crucial. This paper evaluates LLMs' reasoning abilities in competitive environments through game-theoretic tasks, e.g., board and card games that require pure logic and strategic reasoning to compete with opponents. We first propose GTBench, a language-driven environment composing 10 widely-recognized tasks, across a comprehensive game taxonomy: complete versus incomplete information, dynamic versus static, and probabilistic versus deterministic scenarios. Then, we investigate two key problems: (1) Characterizing game-theoretic reasoning of LLMs; (2) LLM-vs-LLM competitions as reasoning evaluation. We observe that (1) LLMs have distinct behaviors regarding various gaming scenarios; for example, LLMs fail in complete and deterministic games yet they are competitive in probabilistic gaming scenarios; (2) Open-source LLMs, e.g., CodeLlama-34b-Instruct, are less competitive than commercial LLMs, e.g., GPT-4, in complex games. In addition, code-pretraining greatly benefits strategic reasoning, while advanced reasoning methods such as Chain-of-Thought (CoT) and Tree-of-Thought (ToT) do not always help. Detailed error profiles are also provided for a better understanding of LLMs' behavior.","Mon, 19 Feb 2024 18:23:36 UTC (6,630 KB)"
"12","KARL: Knowledge-Aware Retrieval and Representations aid Retention and Learning in Students","Matthew Shu, Nishant Balepur, Shi Feng, Jordan Boyd-Graber","Computation and Language (cs.CL)","Flashcard schedulers are tools that rely on 1) student models to predict the flashcards a student knows; and 2) teaching policies to schedule cards based on these predictions. Existing student models, however, only use flashcard-level features, like the student's past responses, ignoring the semantic ties of flashcards. Deep Knowledge Tracing (DKT) models can capture semantic relations with language models, but are inefficient, lack content-rich datasets for evaluation, and require robust teaching policies. To address these issues, we design KARL, a DKT-inspired student model that uses retrieval and BERT embeddings for efficient and accurate student recall predictions. To test KARL, we collect a new dataset of diverse study history on trivia questions. KARL bests existing student models in AUC and calibration error. Finally, we propose a novel teaching policy that exploits the predictive power of DKT models to deploy KARL online. Based on 27 learners and 32 6-day study trajectories, KARL shows the ability to enhance medium-term educational learning, proving its efficacy for scheduling.","Mon, 19 Feb 2024 17:05:29 UTC (8,489 KB)"
"13","A Trembling House of Cards? Mapping Adversarial Attacks against Language Agents","Lingbo Mo, Zeyi Liao, Boyuan Zheng, Yu Su, Chaowei Xiao, Huan Sun","Computation and Language (cs.CL)","Language agents powered by large language models (LLMs) have seen exploding development. Their capability of using language as a vehicle for thought and communication lends an incredible level of flexibility and versatility. People have quickly capitalized on this capability to connect LLMs to a wide range of external components and environments: databases, tools, the Internet, robotic embodiment, etc. Many believe an unprecedentedly powerful automation technology is emerging. However, new automation technologies come with new safety risks, especially for intricate systems like language agents. There is a surprisingly large gap between the speed and scale of their development and deployment and our understanding of their safety risks. Are we building a house of cards? In this position paper, we present the first systematic effort in mapping adversarial attacks against language agents. We first present a unified conceptual framework for agents with three major components: Perception, Brain, and Action. Under this framework, we present a comprehensive discussion and propose 12 potential attack scenarios against different components of an agent, covering different attack strategies (e.g., input manipulation, adversarial demonstrations, jailbreaking, backdoors). We also draw connections to successful attack strategies previously applied to LLMs. We emphasize the urgency to gain a thorough understanding of language agent risks before their widespread deployment.","Thu, 15 Feb 2024 18:51:32 UTC (9,676 KB)"
"14","Symmetry-Breaking Augmentations for Ad Hoc Teamwork","Ravi Hammond, Dustin Craggs, Mingyu Guo, Jakob Foerster, Ian Reid","Machine Learning (cs.LG)","In many collaborative settings, artificial intelligence (AI) agents must be able to adapt to new teammates that use unknown or previously unobserved strategies. While often simple for humans, this can be challenging for AI agents. For example, if an AI agent learns to drive alongside others (a training set) that only drive on one side of the road, it may struggle to adapt this experience to coordinate with drivers on the opposite side, even if their behaviours are simply flipped along the left-right symmetry. To address this we introduce symmetry-breaking augmentations (SBA), which increases diversity in the behaviour of training teammates by applying a symmetry-flipping operation. By learning a best-response to the augmented set of teammates, our agent is exposed to a wider range of behavioural conventions, improving performance when deployed with novel teammates. We demonstrate this experimentally in two settings, and show that our approach improves upon previous ad hoc teamwork results in the challenging card game Hanabi. We also propose a general metric for estimating symmetry-dependency amongst a given set of policies.","Thu, 15 Feb 2024 14:49:28 UTC (2,080 KB)"
"15","Enumeration of multiplex juggling card sequences using generalized q-derivatives","Yumin Cho, Jaehyun Kim, Jang Soo Kim, Nakyung Lee","Combinatorics (math.CO)","In 2019, Butler, Choi, Kim, and Seo introduced a new type of juggling card that represents multiplex juggling patterns in a natural bijective way. They conjectured a formula for the generating function for the number of multiplex juggling cards with capacity 2. In this paper we prove their conjecture. More generally, we find an explicit formula for the generating function with any capacity. We also find an expression for the generating function for multiplex juggling card sequences by introducing a generalization of the q-derivative operator. As a consequence, we show that this generating function is a rational function.","Thu, 15 Feb 2024 12:05:14 UTC (13 KB)"
"16","Rationality Report Cards: Assessing the Economic Rationality of Large Language Models","Narun Raman, Taylor Lundy, Samuel Amouyal, Yoav Levine, Kevin Leyton-Brown, Moshe Tennenholtz","Computation and Language (cs.CL)","There is increasing interest in using LLMs as decision-making ""agents."" Doing so includes many degrees of freedom: which model should be used; how should it be prompted; should it be asked to introspect, conduct chain-of-thought reasoning, etc? Settling these questions -- and more broadly, determining whether an LLM agent is reliable enough to be trusted -- requires a methodology for assessing such an agent's economic rationality. In this paper, we provide one. We begin by surveying the economic literature on rational decision making, taxonomizing a large set of fine-grained ""elements"" that an agent should exhibit, along with dependencies between them. We then propose a benchmark distribution that quantitatively scores an LLMs performance on these elements and, combined with a user-provided rubric, produces a ""rationality report card."" Finally, we describe the results of a large-scale empirical experiment with 14 different LLMs, characterizing the both current state of the art and the impact of different model sizes on models' ability to exhibit rational behavior.","Wed, 14 Feb 2024 20:05:26 UTC (5,177 KB)"
"17","JAX-Fluids 2.0: Towards HPC for Differentiable CFD of Compressible Two-phase Flows","Deniz A. Bezgin, Aaron B. Buhendwa, Nikolaus A. Adams","Fluid Dynamics (physics.flu-dyn)","In our effort to facilitate machine learning-assisted computational fluid dynamics (CFD), we introduce the second iteration of JAX-Fluids. JAX-Fluids is a Python-based fully-differentiable CFD solver designed for compressible single- and two-phase flows. In this work, the first version is extended to incorporate high-performance computing (HPC) capabilities. We introduce a parallelization strategy utilizing JAX primitive operations that scales efficiently on GPU (up to 512 NVIDIA A100 graphics cards) and TPU (up to 1024 TPU v3 cores) HPC systems. We further demonstrate the stable parallel computation of automatic differentiation gradients across extended integration trajectories. The new code version offers enhanced two-phase flow modeling capabilities. In particular, a five-equation diffuse-interface model is incorporated which complements the level-set sharp-interface model. Additional algorithmic improvements include positivity-preserving limiters for increased robustness, support for stretched Cartesian meshes, refactored I/O handling, comprehensive post-processing routines, and an updated list of state-of-the-art high-order numerical discretization schemes. We verify newly added numerical models by showcasing simulation results for single- and two-phase flows, including turbulent boundary layer and channel flows, air-helium shock bubble interactions, and air-water shock drop interactions.","Wed, 7 Feb 2024 19:05:27 UTC (43,665 KB)"
"18","What's documented in AI? Systematic Analysis of 32K AI Model Cards","Weixin Liang, Nazneen Rajani, Xinyu Yang, Ezinwanne Ozoani, Eric Wu, Yiqun Chen, Daniel Scott Smith, James Zou","Software Engineering (cs.SE)","The rapid proliferation of AI models has underscored the importance of thorough documentation, as it enables users to understand, trust, and effectively utilize these models in various applications. Although developers are encouraged to produce model cards, it's not clear how much information or what information these cards contain. In this study, we conduct a comprehensive analysis of 32,111 AI model documentations on Hugging Face, a leading platform for distributing and deploying AI models. Our investigation sheds light on the prevailing model card documentation practices. Most of the AI models with substantial downloads provide model cards, though the cards have uneven informativeness. We find that sections addressing environmental impact, limitations, and evaluation exhibit the lowest filled-out rates, while the training section is the most consistently filled-out. We analyze the content of each section to characterize practitioners' priorities. Interestingly, there are substantial discussions of data, sometimes with equal or even greater emphasis than the model itself. To evaluate the impact of model cards, we conducted an intervention study by adding detailed model cards to 42 popular models which had no or sparse model cards previously. We find that adding model cards is moderately correlated with an increase weekly download rates. Our study opens up a new perspective for analyzing community norms and practices for model documentation through large-scale data science and linguistics analysis.","Wed, 7 Feb 2024 18:04:32 UTC (3,251 KB)"
"19","The QISG suite: high-performance codes for studying Quantum Ising Spin Glasses","Massimo Bernaschi, Isidoro González-Adalid Pemartín, Víctor Martín-Mayor, Giorgio Parisi","Computational Physics (physics.comp-ph)","We release a set of GPU programs for the study of the Quantum ($S=1/2$) Spin Glass on a square lattice, with binary couplings. The library contains two main codes: MCQSG (that carries out Monte Carlo simulations using both the Metropolis and the Parallel Tempering algorithms, for the problem formulated in the Trotter-Suzuki approximation), and EDQSG (that obtains the extremal eigenvalues of the Transfer Matrix using the Lanczos algorithm). EDQSG has allowed us to diagonalize transfer matrices with size up to $2^{36}\times2^{36}$. From its side, MCQSG running on four NVIDIA A100 cards delivers a sub-picosecond time per spin-update, a performance that is competitive with dedicated hardware. We include as well in our library GPU programs for the analysis of the spin configurations generated by MCQSG. Finally, we provide two auxiliary codes: the first generates the lookup tables employed by the random number generator of MCQSG; the second one simplifies the execution of multiple runs using different input data.","Tue, 6 Feb 2024 11:40:53 UTC (214 KB)"
"20","Reverse Engineering and Security Evaluation of Commercial Tags for RFID-Based IoT Applications","Tiago M. Fernández-Caramés, Paula Fraga-Lamas, Manuel Suárez-Albela, Luis Castedo","Systems and Control (eess.SY)","The Internet of Things (IoT) is a distributed system of physical objects that requires the seamless integration of hardware (e.g., sensors, actuators, electronics) and network communications in order to collect and exchange data. IoT smart objects need to be somehow identified to determine the origin of the data and to automatically detect the elements around us. One of the best positioned technologies to perform identification is RFID (Radio Frequency Identification), which in the last years has gained a lot of popularity in applications like access control, payment cards or logistics. Despite its popularity, RFID security has not been properly handled in numerous applications. To foster security in such applications, this article includes three main contributions. First, in order to establish the basics, a detailed review of the most common flaws found in RFID-based IoT systems is provided, including the latest attacks described in the literature. Second, a novel methodology that eases the detection and mitigation of such flaws is presented. Third, the latest RFID security tools are analyzed and the methodology proposed is applied through one of them (Proxmark 3) to validate it. Thus, the methodology is tested in different scenarios where tags are commonly used for identification. In such systems it was possible to clone transponders, extract information, and even emulate both tags and readers. Therefore, it is shown that the methodology proposed is useful for auditing security and reverse engineering RFID communications in IoT applications. It must be noted that, although this paper is aimed at fostering RFID communications security in IoT applications, the methodology can be applied to any RFID communications protocol.","Mon, 5 Feb 2024 23:55:46 UTC (3,784 KB)"
"21","Probing Planck scale physics with Belle II and LHCb","Ashutosh Kumar Alok, Subhashish Banerjee, Neetu Raj Singh Chundawat, S. Uma Sankar","High Energy Physics - Phenomenology (hep-ph)","With the advent of Belle II and the LHCb upgrade, the precision measurements of various B-Physics observables are on cards. This holds significant potential for delving into physics beyond the standard model of electroweak interactions. These measurements can also serve as means to establish limits on phenomena occurring at much finer length scales, such as quantum decoherence, which may arise due to potential discreteness in space-time or non-trivial topological effects. In this work, we set up the formalism to investigate the impact of quantum decoherence on several potential observables in $B$ meson systems. The approach employs the trace-preserving Kraus operator formalism, extending unitary evolution to non-unitary dynamics while maintaining complete positivity. In this formalism, the decoherence effects are parametrized in terms of a single parameter. Through the analysis of purely leptonic, semileptonic, and non-leptonic decays of $B$ mesons, we identify observables that could, in principle, be influenced by decoherence. The theoretical expressions are provided without neglecting the impact of decay width difference ($\Delta \Gamma$) and $CP$ violation in mixing. Considering that many of these observables can be measured with high precision using the abundant data collected by LHCb and Belle II, our formalism can be applied to establish constraints on the decoherence parameter through multiple decay channels. This offers an alternative set-up for such studies, which, at present, are predominantly conducted in the neutrino sector.","Sun, 4 Feb 2024 13:02:48 UTC (38 KB)"
"22","Navigate Biopsy with Ultrasound under Augmented Reality Device: Towards Higher System Performance","Haowei Li, Wenqing Yan, Jiasheng Zhao, Yuqi Ji, Long Qian, Hui Ding, Zhe Zhao, Guangzhi Wang","Human-Computer Interaction (cs.HC)","Purpose: Biopsies play a crucial role in determining the classification and staging of tumors. Ultrasound is frequently used in this procedure to provide real-time anatomical information. Using augmented reality (AR), surgeons can visualize ultrasound data and spatial navigation information seamlessly integrated with real tissues. This innovation facilitates faster and more precise biopsy operations. Methods: We developed an AR biopsy navigation system with low display latency and high accuracy. Ultrasound data is initially read by an image capture card and streamed to Unity via net communication. In Unity, navigation information is rendered and transmitted to the HoloLens 2 device using holographic remoting. Retro-reflective tool tracking is implemented on the HoloLens 2, enabling simultaneous tracking of the ultrasound probe and biopsy needle. Distinct navigation information is provided during in-plane and out-of-plane punctuation. To evaluate the effectiveness of our system, we conducted a study involving ten participants, for puncture accuracy and biopsy time, comparing to traditional methods. Results: Our proposed framework enables ultrasound visualization in AR with only $16.22\pm11.45ms$ additional latency. Navigation accuracy reached $1.23\pm 0.68mm$ in the image plane and $0.95\pm 0.70mm$ outside the image plane. Remarkably, the utilization of our system led to $98\%$ and $95\%$ success rate in out-of-plane and in-plane biopsy. Conclusion: To sum up, this paper introduces an AR-based ultrasound biopsy navigation system characterized by high navigation accuracy and minimal latency. The system provides distinct visualization contents during in-plane and out-of-plane operations according to their different characteristics. Use case study in this paper proved that our system can help young surgeons perform biopsy faster and more accurately.","Sun, 4 Feb 2024 09:18:43 UTC (5,810 KB)"
"23","Spin: An Efficient Secure Computation Framework with GPU Acceleration","Wuxuan Jiang, Xiangjun Song, Shenbai Hong, Haijun Zhang, Wenxin Liu, Bo Zhao, Wei Xu, Yi Li","Cryptography and Security (cs.CR)","Accuracy and efficiency remain challenges for multi-party computation (MPC) frameworks. Spin is a GPU-accelerated MPC framework that supports multiple computation parties and a dishonest majority adversarial setup. We propose optimized protocols for non-linear functions that are critical for machine learning, as well as several novel optimizations specific to attention that is the fundamental unit of Transformer models, allowing Spin to perform non-trivial CNNs training and Transformer inference without sacrificing security. At the backend level, Spin leverages GPU, CPU, and RDMA-enabled smart network cards for acceleration. Comprehensive evaluations demonstrate that Spin can be up to $2\times$ faster than the state-of-the-art for deep neural network training. For inference on a Transformer model with 18.9 million parameters, our attention-specific optimizations enable Spin to achieve better efficiency, less communication, and better accuracy.","Sun, 4 Feb 2024 02:12:15 UTC (415 KB)[v2] Sat, 24 Feb 2024 04:49:28 UTC (415 KB)"
"24","ExTTNet: A Deep Learning Algorithm for Extracting Table Texts from Invoice Images","Adem Akdoğan, Murat Kurt","Computer Vision and Pattern Recognition (cs.CV)","In this work, product tables in invoices are obtained autonomously via a deep learning model, which is named as ExTTNet. Firstly, text is obtained from invoice images using Optical Character Recognition (OCR) techniques. Tesseract OCR engine [37] is used for this process. Afterwards, the number of existing features is increased by using feature extraction methods to increase the accuracy. Labeling process is done according to whether each text obtained as a result of OCR is a table element or not. In this study, a multilayer artificial neural network model is used. The training has been carried out with an Nvidia RTX 3090 graphics card and taken $162$ minutes. As a result of the training, the F1 score is $0.92$.","Sat, 3 Feb 2024 19:24:45 UTC (1,010 KB)"
"25","The effect of diversity on group decision-making","Georgi Karadzhov, Andreas Vlachos, Tom Stafford","Computation and Language (cs.CL)","We explore different aspects of cognitive diversity and its effect on the success of group deliberation. To evaluate this, we use 500 dialogues from small, online groups discussing the Wason Card Selection task - the DeliData corpus. Leveraging the corpus, we perform quantitative analysis evaluating three different measures of cognitive diversity. First, we analyse the effect of group size as a proxy measure for diversity. Second, we evaluate the effect of the size of the initial idea pool. Finally, we look into the content of the discussion by analysing discussed solutions, discussion patterns, and how conversational probing can improve those characteristics. Despite the reputation of groups for compounding bias, we show that small groups can, through dialogue, overcome intuitive biases and improve individual decision-making. Across a large sample and different operationalisations, we consistently find that greater cognitive diversity is associated with more successful group deliberation. Code and data used for the analysis are available in the anonymised repository: https://anonymous.4open.science/ r/cogsci24-FD6D","Fri, 2 Feb 2024 14:15:01 UTC (10,647 KB)"
"26","Can we Constrain Concept Bottleneck Models to Learn Semantically Meaningful Input Features?","Jack Furby, Daniel Cunnington, Dave Braines, Alun Preece","Machine Learning (cs.LG)","Concept Bottleneck Models (CBMs) are considered inherently interpretable because they first predict a set of human-defined concepts before using these concepts to predict the output of a downstream task. For inherent interpretability to be fully realised, and ensure trust in a model's output, we need to guarantee concepts are predicted based on semantically mapped input features. For example, one might expect the pixels representing a broken bone in an image to be used for the prediction of a fracture. However, current literature indicates this is not the case, as concept predictions are often mapped to irrelevant input features. We hypothesise that this occurs when concept annotations are inaccurate or how input features should relate to concepts is unclear. In general, the effect of dataset labelling on concept representations in CBMs remains an understudied area. Therefore, in this paper, we examine how CBMs learn concepts from datasets with fine-grained concept annotations. We demonstrate that CBMs can learn concept representations with semantic mapping to input features by removing problematic concept correlations, such as two concepts always appearing together. To support our evaluation, we introduce a new synthetic image dataset based on a playing cards domain, which we hope will serve as a benchmark for future CBM research. For validation, we provide empirical evidence on a real-world dataset of chest X-rays, to demonstrate semantically meaningful concepts can be learned in real-world applications.","Thu, 1 Feb 2024 10:18:43 UTC (40,372 KB)"
"27","Coherent Feed Forward Quantum Neural Network","Utkarsh Singh, Aaron Z. Goldberg, Khabat Heshami","Quantum Physics (quant-ph)","Quantum machine learning, focusing on quantum neural networks (QNNs), remains a vastly uncharted field of study. Current QNN models primarily employ variational circuits on an ansatz or a quantum feature map, often requiring multiple entanglement layers. This methodology not only increases the computational cost of the circuit beyond what is practical on near-term quantum devices but also misleadingly labels these models as neural networks, given their divergence from the structure of a typical feed-forward neural network (FFNN). Moreover, the circuit depth and qubit needs of these models scale poorly with the number of data features, resulting in an efficiency challenge for real-world machine-learning tasks. We introduce a bona fide QNN model, which seamlessly aligns with the versatility of a traditional FFNN in terms of its adaptable intermediate layers and nodes, absent from intermediate measurements such that our entire model is coherent. This model stands out with its reduced circuit depth and number of requisite C-NOT gates to outperform prevailing QNN models. Furthermore, the qubit count in our model remains unaffected by the data's feature quantity. We test our proposed model on various benchmarking datasets such as the diagnostic breast cancer (Wisconsin) and credit card fraud detection datasets. We compare the outcomes of our model with the existing QNN methods to showcase the advantageous efficacy of our approach, even with a reduced requirement on quantum resources. Our model paves the way for application of quantum neural networks to real relevant machine learning problems.","Thu, 1 Feb 2024 15:13:26 UTC (518 KB)"
"28","The Influence of Presentation and Performance on User Satisfaction","Kanaad Pathak, Leif Azzopardi, Martin Halvey","Human-Computer Interaction (cs.HC)","The effectiveness of an IR system is gauged not just by its ability to retrieve relevant results but also by how it presents these results to users; an engaging presentation often correlates with increased user satisfaction. While existing research has delved into the link between user satisfaction, IR performance metrics, and presentation, these aspects have typically been investigated in isolation. Our research aims to bridge this gap by examining the relationship between query performance, presentation and user satisfaction. For our analysis, we conducted a between-subjects experiment comparing the effectiveness of various result card layouts for an ad-hoc news search interface. Drawing data from the TREC WaPo 2018 collection, we centered our study on four specific topics. Within each of these topics, we assessed six distinct queries with varying nDCG values. Our study involved 164 participants who were exposed to one of five distinct layouts containing result cards, such as ""title'', ""title+image'', or ""title+image+summary''. Our findings indicate that while nDCG is a strong predictor of user satisfaction at the query level, there exists no linear relationship between the performance of the query, presentation of results and user satisfaction. However, when considering the total gain on the initial result page, we observed that presentation does play a significant role in user satisfaction (at the query level) for certain layouts with result cards such as, title+image or title+image+summary. Our results also suggest that the layout differences have complex and multifaceted impacts on satisfaction. We demonstrate the capacity to equalize user satisfaction levels between queries of varying performance by changing how results are presented. This emphasizes the necessity to harmonize both performance and presentation in IR systems, considering users' diverse preferences.","Tue, 30 Jan 2024 15:32:56 UTC (6,339 KB)"
"29","No Longer Trending on Artstation: Prompt Analysis of Generative AI Art","Jon McCormack, Maria Teresa Llano, Stephen James Krol, Nina Rajcic","Human-Computer Interaction (cs.HC)","Image generation using generative AI is rapidly becoming a major new source of visual media, with billions of AI generated images created using diffusion models such as Stable Diffusion and Midjourney over the last few years. In this paper we collect and analyse over 3 million prompts and the images they generate. Using natural language processing, topic analysis and visualisation methods we aim to understand collectively how people are using text prompts, the impact of these systems on artists, and more broadly on the visual cultures they promote. Our study shows that prompting focuses largely on surface aesthetics, reinforcing cultural norms, popular conventional representations and imagery. We also find that many users focus on popular topics (such as making colouring books, fantasy art, or Christmas cards), suggesting that the dominant use for the systems analysed is recreational rather than artistic.","Wed, 24 Jan 2024 08:03:13 UTC (2,093 KB)"
"30","Navigating Dataset Documentations in AI: A Large-Scale Analysis of Dataset Cards on Hugging Face","Xinyu Yang, Weixin Liang, James Zou","Machine Learning (cs.LG)","Advances in machine learning are closely tied to the creation of datasets. While data documentation is widely recognized as essential to the reliability, reproducibility, and transparency of ML, we lack a systematic empirical understanding of current dataset documentation practices. To shed light on this question, here we take Hugging Face -- one of the largest platforms for sharing and collaborating on ML models and datasets -- as a prominent case study. By analyzing all 7,433 dataset documentation on Hugging Face, our investigation provides an overview of the Hugging Face dataset ecosystem and insights into dataset documentation practices, yielding 5 main findings: (1) The dataset card completion rate shows marked heterogeneity correlated with dataset popularity. (2) A granular examination of each section within the dataset card reveals that the practitioners seem to prioritize Dataset Description and Dataset Structure sections, while the Considerations for Using the Data section receives the lowest proportion of content. (3) By analyzing the subsections within each section and utilizing topic modeling to identify key topics, we uncover what is discussed in each section, and underscore significant themes encompassing both technical and social impacts, as well as limitations within the Considerations for Using the Data section. (4) Our findings also highlight the need for improved accessibility and reproducibility of datasets in the Usage sections. (5) In addition, our human annotation evaluation emphasizes the pivotal role of comprehensive dataset content in shaping individuals' perceptions of a dataset card's overall quality. Overall, our study offers a unique perspective on analyzing dataset documentation through large-scale data science analysis and underlines the need for more thorough dataset documentation in machine learning research.","Wed, 24 Jan 2024 21:47:13 UTC (2,660 KB)"
"31","A Big Data Architecture for Early Identification and Categorization of Dark Web Sites","Javier Pastor-Galindo, Hông-Ân Sandlin, Félix Gómez Mármol, Gérôme Bovet, Gregorio Martínez Pérez","Distributed, Parallel, and Cluster Computing (cs.DC)","The dark web has become notorious for its association with illicit activities and there is a growing need for systems to automate the monitoring of this space. This paper proposes an end-to-end scalable architecture for the early identification of new Tor sites and the daily analysis of their content. The solution is built using an Open Source Big Data stack for data serving with Kubernetes, Kafka, Kubeflow, and MinIO, continuously discovering onion addresses in different sources (threat intelligence, code repositories, web-Tor gateways, and Tor repositories), downloading the HTML from Tor and deduplicating the content using MinHash LSH, and categorizing with the BERTopic modeling (SBERT embedding, UMAP dimensionality reduction, HDBSCAN document clustering and c-TF-IDF topic keywords). In 93 days, the system identified 80,049 onion services and characterized 90% of them, addressing the challenge of Tor volatility. A disproportionate amount of repeated content is found, with only 6.1% unique sites. From the HTML files of the dark sites, 31 different low-topics are extracted, manually labeled, and grouped into 11 high-level topics. The five most popular included sexual and violent content, repositories, search engines, carding, cryptocurrencies, and marketplaces. During the experiments, we identified 14 sites with 13,946 clones that shared a suspiciously similar mirroring rate per day, suggesting an extensive common phishing network. Among the related works, this study is the most representative characterization of onion services based on topics to date.","Wed, 24 Jan 2024 09:30:21 UTC (644 KB)"
"32","Small Language Model Meets with Reinforced Vision Vocabulary","Haoran Wei, Lingyu Kong, Jinyue Chen, Liang Zhao, Zheng Ge, En Yu, Jianjian Sun, Chunrui Han, Xiangyu Zhang","Computer Vision and Pattern Recognition (cs.CV)","Playing Large Vision Language Models (LVLMs) in 2023 is trendy among the AI community. However, the relatively large number of parameters (more than 7B) of popular LVLMs makes it difficult to train and deploy on consumer GPUs, discouraging many researchers with limited resources. Imagine how cool it would be to experience all the features of current LVLMs on an old GTX1080ti (our only game card). Accordingly, we present Vary-toy in this report, a small-size Vary along with Qwen-1.8B as the base ``large'' language model. In Vary-toy, we introduce an improved vision vocabulary, allowing the model to not only possess all features of Vary but also gather more generality. Specifically, we replace negative samples of natural images with positive sample data driven by object detection in the procedure of generating vision vocabulary, more sufficiently utilizing the capacity of the vocabulary network and enabling it to efficiently encode visual information corresponding to natural objects. For experiments, Vary-toy can achieve 65.6% ANLS on DocVQA, 59.1% accuracy on ChartQA, 88.1% accuracy on RefCOCO, and 29% on MMVet. The code will be publicly available on the homepage.","Tue, 23 Jan 2024 05:55:26 UTC (3,107 KB)"
"33","A new game with Quark Matter Cards:Interactions of elementary particles","Ana Uzelac","Physics Education (physics.ed-ph)","This paper introduces a card game called ""Quark Matter Card Games,"" inspired by the creativity of a high school student, Csaba Török, and developed in collaboration with physicist Tamás Csörgő. The game utilizes a deck of 66 cards representing elementary particles and antiparticles, offering an entertaining way to popularize science and introduce players to particle physics concepts. The initial edition includes games exploring topics like baryon formation, mesons, quark colors, and more. The author proposes a new game focusing on the four fundamental forces. Players must strategically place cards on a central card, simulating interactions based on strong, electromagnetic, weak, and gravitational forces. Specific rules for particle placement, including fundamental forces, annihilation and neutrino oscillations are elucidated. Additional rules and conditions add complexity and strategy to the game, ensuring active engagement. The intended audience ranges from individuals familiar with particle physics to those new to the field. The game provides an engaging platform for learning about elementary particle interactions, with varying levels of complexity. The paper discusses the educational potential, offering suggestions for simplified versions. Furthermore, all necessary concepts are briefly explained, and the physical background of the game is provided. The paper concludes with topics for further discussions, linking game experiences to particle physics concepts. Questions cover gravitational interaction interpretations, differentiation between quarks and leptons, explanations of weak and electromagnetic interactions and more. The acknowledgment section expresses gratitude to mentors and pioneers of card games with elementary particles for their inspiration and support.","Sat, 30 Dec 2023 15:59:03 UTC (838 KB)"
"34","Investigating Fouling Efficiency in Football Using Expected Booking (xB) Model","Adnan Azmat, Su Su Yi","Machine Learning (cs.LG)","This paper introduces the Expected Booking (xB) model, a novel metric designed to estimate the likelihood of a foul resulting in a yellow card in football. Through three iterative experiments, employing ensemble methods, the model demonstrates improved performance with additional features and an expanded dataset. Analysis of FIFA World Cup 2022 data validates the model's efficacy in providing insights into team and player fouling tactics, aligning with actual defensive performance. The xB model addresses a gap in fouling efficiency examination, emphasizing defensive strategies which often overlooked. Further enhancements are suggested through the incorporation of comprehensive data and spatial features.","Tue, 16 Jan 2024 05:21:51 UTC (514 KB)"
"35","Ranking Heterogeneous Search Result Pages using the Interactive Probability Ranking Principle","Kanaad Pathak, Leif Azzopardi, Martin Halvey","Information Retrieval (cs.IR)","The Probability Ranking Principle (PRP) ranks search results based on their expected utility derived solely from document contents, often overlooking the nuances of presentation and user interaction. However, with the evolution of Search Engine Result Pages (SERPs), now comprising a variety of result cards, the manner in which these results are presented is pivotal in influencing user engagement and satisfaction. This shift prompts the question: How does the PRP and its user-centric counterpart, the Interactive Probability Ranking Principle (iPRP), compare in the context of these heterogeneous SERPs? Our study draws a comparison between the PRP and the iPRP, revealing significant differences in their output. The iPRP, accounting for item-specific costs and interaction probabilities to determine the ``Expected Perceived Utility"" (EPU), yields different result orderings compared to the PRP. We evaluate the effect of the EPU on the ordering of results by observing changes in the ranking within a heterogeneous SERP compared to the traditional ``ten blue links''. We find that changing the presentation affects the ranking of items according to the (iPRP) by up to 48\% (with respect to DCG, TBG and RBO) in ad-hoc search tasks on the TREC WaPo Collection. This work suggests that the iPRP should be employed when ranking heterogeneous SERPs to provide a user-centric ranking that adapts the ordering based on the presentation and user engagement.","Tue, 16 Jan 2024 10:41:09 UTC (3,317 KB)"
"36","Cash and Card Acceptance in Retail Payments: Motivations and Factors","Samuel Vandak, Geoffrey Goodell","Computers and Society (cs.CY)","The landscape of payment methods in retail is a complex and evolving area. Vendors are motivated to conduct an appropriate analysis to decide what payment methods to accept out of a vast range of options. Many factors are included in this decision process, some qualitative and some quantitative. The following research project investigates vendors' acceptance of cards and cash from various viewpoints, all chosen to represent a novel perspective, including the barriers and preferences for each and correlations with external demographic factors. We observe that lower interchange fees, limited in this instance by the regulatory framework, play a crucial role in facilitating merchants' acceptance of card payments. The regulatory constraints on interchange fees create a favorable cost structure for merchants, making card payment adoption financially feasible. However, additional factors like technological readiness and consumer preferences might also play a significant role in their decision-making process. We also note that aggregate Merchant Service Providers (MSPs) have positively impacted the payment landscape by offering more competitive fee rates, particularly beneficial for small merchants and entrepreneurs. However, associated risks, such as account freezes or abrupt terminations, pose challenges and often lack transparency. Last, the quantitative analysis of the relationship between demographic variables and acceptance of payment types is presented. This analysis combines the current landscape of payment acceptance in the UK with data from the most recent census from 2021. We show that the unemployment rates shape card and cash acceptance, age affects contactless preference, and work-from-home impacts credit card preference.","Mon, 15 Jan 2024 13:48:58 UTC (7,948 KB)"
"37","Performance Evaluation of Neuromorphic Hardware for Onboard Satellite Communication Applications","Eva Lagunas, Flor Ortiz, Geoffrey Eappen, Saed Daoud, Wallace Alves Martins, Jorge Querol, Symeon Chatzinotas, Nicolas Skatchkovsky, Bipin Rajendran, Osvaldo Simeone","Signal Processing (eess.SP)","Spiking neural networks (SNNs) implemented on neuromorphic processors (NPs) can enhance the energy efficiency of deployments of artificial intelligence (AI) for specific workloads. As such, NP represents an interesting opportunity for implementing AI tasks on board power-limited satellite communication spacecraft. In this article, we disseminate the findings of a recently completed study which targeted the comparison in terms of performance and power-consumption of different satellite communication use cases implemented on standard AI accelerators and on NPs. In particular, the article describes three prominent use cases, namely payload resource optimization, onboard interference detection and classification, and dynamic receive beamforming; and compare the performance of conventional convolutional neural networks (CNNs) implemented on Xilinx's VCK5000 Versal development card and SNNs on Intel's neuromorphic chip Loihi 2.","Fri, 12 Jan 2024 21:56:57 UTC (5,331 KB)"
"38","eSIM Technology in IoT Architecture","Hang Yuan, Artiom Baloian, Jan Janak, Henning Schulzrinne","Networking and Internet Architecture (cs.NI)","eSIM(embedded SIM) is an advanced alternative to traditional physical SIM cards initially developed by the GSM Association(GSMA) in 2013 [1][2]. The eSIM technology has been deployed in many commercial products such as mobile devices. However, the application of the eSIM technology in IoT devices has yet to start being primarily deployed. Understanding the eSIM architecture and the basic ideas of the eSIM provisioning and operations is very important for engineers to promote eSIM technology deployment in more areas, both academics and industries. The report focuses on the eSIM technology in the IoT architecture and two major operations of Remote SIM Provisioning(RSP) procedure: the Common Mutual Authentication procedure, a process used to authenticate eSIM trusted communication parties over the public internet, and the Profile Downloading procedure, the way to download the Profile from the operator SM-DP+ server and eventually remotely provision the end-user devices.","Tue, 9 Jan 2024 01:19:47 UTC (532 KB)"
"39","Primitive elements in infinitesimal bialgebras","Dalia Artenstein, Ana González, María Ronco","Combinatorics (math.CO)","For any set S, the free magmatic algebra spanned by card(S) binary products is the vector space spanned by the set of all planar rooted binary trees with the internal nodes colored by the elements of S, graded by the number of leaves of a tree. We show that it has a unique structure of coassociative coalgebra such that the coproduct satisfies the unital infinitesimal condition with each magmatic product, and prove an analog of Aguiar-Sottile formula in this context, describing the coproduct in terms of the Moebius basis for the Tamari order. The last result allows us to compute the subspace of primitive elements of any unital infinitesimal S-magmatic bialgebra. As an example, we construct a set of generators of the dual of Pilaud and Pons bialgebra of integer relations and compute an explicit basis of its subspace of primitive elements.","Wed, 3 Jan 2024 18:58:28 UTC (278 KB)"
"40","Towards a Foundation Purchasing Model: Pretrained Generative Autoregression on Transaction Sequences","Piotr Skalski, David Sutton, Stuart Burrell, Iker Perez, Jason Wong","Machine Learning (cs.LG)","Machine learning models underpin many modern financial systems for use cases such as fraud detection and churn prediction. Most are based on supervised learning with hand-engineered features, which relies heavily on the availability of labelled data. Large self-supervised generative models have shown tremendous success in natural language processing and computer vision, yet so far they haven't been adapted to multivariate time series of financial transactions. In this paper, we present a generative pretraining method that can be used to obtain contextualised embeddings of financial transactions. Benchmarks on public datasets demonstrate that it outperforms state-of-the-art self-supervised methods on a range of downstream tasks. We additionally perform large-scale pretraining of an embedding model using a corpus of data from 180 issuing banks containing 5.1 billion transactions and apply it to the card fraud detection problem on hold-out datasets. The embedding model significantly improves value detection rate at high precision thresholds and transfers well to out-of-domain distributions.","Wed, 3 Jan 2024 09:32:48 UTC (642 KB)[v2] Thu, 4 Jan 2024 16:52:11 UTC (642 KB)"
"41","$Φ$ index: A standardized scale-independent citation indicator","Manolis Antonoyiannakis","Digital Libraries (cs.DL)","The sensitivity of Impact Factors (IFs) to journal size causes systematic bias in IF rankings, in a process akin to {\it stacking the cards}: A random ``journal'' of $n$ papers can attain a range of IF values that decreases rapidly with size, as $\sim 1/\sqrt{n}$ . The Central Limit Theorem, which underlies this effect, also allows us to correct it by standardizing citation averages for scale {\it and} subject in a geometrically intuitive manner analogous to calculating the $z$-score. We thus propose the $\Phi$ index, a standardized scale- and subject-independent citation average. The $\Phi$ index passes the ``random sample test'', a simple check for scale and subject independence that we argue ought to be used for every citation indicator. We present $\Phi$ index rankings for 12,173 journals using 2020 Journal Citation Reports data. We show how scale standardization alone affects rankings, demonstrate the additional effect of subject standardization for monodisciplinary journals, and discuss how to treat multidisciplinary journals. $\Phi$ index rankings offer a clear improvement over IF rankings. And because the $\Phi$ index methodology is general, it can also be applied to compare individual researchers, universities, or countries.","Tue, 2 Jan 2024 02:39:11 UTC (514 KB)"
"42","Improve Fidelity and Utility of Synthetic Credit Card Transaction Time Series from Data-centric Perspective","Din-Yin Hsieh, Chi-Hua Wang, Guang Cheng","Machine Learning (cs.LG)","Exploring generative model training for synthetic tabular data, specifically in sequential contexts such as credit card transaction data, presents significant challenges. This paper addresses these challenges, focusing on attaining both high fidelity to actual data and optimal utility for machine learning tasks. We introduce five pre-processing schemas to enhance the training of the Conditional Probabilistic Auto-Regressive Model (CPAR), demonstrating incremental improvements in the synthetic data's fidelity and utility. Upon achieving satisfactory fidelity levels, our attention shifts to training fraud detection models tailored for time-series data, evaluating the utility of the synthetic data. Our findings offer valuable insights and practical guidelines for synthetic data practitioners in the finance sector, transitioning from real to synthetic datasets for training purposes, and illuminating broader methodologies for synthesizing credit card transaction time series.","Mon, 1 Jan 2024 22:34:14 UTC (3,973 KB)"
"43","A new game with Quark Matter Cards: The Eightfold path","Ana Uzelac","Physics Education (physics.ed-ph)","This paper introduces an educational card game designed to elucidate fundamental particle physics concepts, specifically emphasizing the classification of hadrons through the ""Eightfold Path."" Derived from the Quark Matter Card Games series, the game entails arranging elementary particle cards to construct baryons and mesons on designated game boards. Detailed rules for beginner and intermediate levels are provided. The game aims to enhance understanding of particle properties, color neutrality, and symmetry principles, integral to the quark model and the Standard Model of particle physics. The paper explores the game's physical background, delving into the historical significance of the Eightfold Way and its contributions to quark theory. Adaptable for various age groups, the game serves as a dynamic and engaging tool for learning intricate physics concepts in an entertaining manner. The conclusion expresses gratitude to mentors and pioneers in the realm of card games featuring elementary particles.","Sat, 30 Dec 2023 16:12:33 UTC (867 KB)"
"44","The Quantum House Of Cards","Xavier Waintal","Quantum Physics (quant-ph)","Quantum computers have been proposed to solve a number of important problems such as discovering new drugs, new catalysts for fertilizer production, breaking encryption protocols, optimizing financial portfolios, or implementing new artificial intelligence applications. Yet, to date, a simple task such as multiplying 3 by 5 is beyond existing quantum hardware. This article examines the difficulties that would need to be solved for quantum computers to live up to their promises. I discuss the whole stack of technologies that has been envisioned to build a quantum computer from the top layers (the actual algorithms and associated applications) down to the very bottom ones (the quantum hardware, its control electronics, cryogeny, etc.) while not forgetting the crucial intermediate layer of quantum error correction.","Fri, 29 Dec 2023 11:48:51 UTC (542 KB)"
"45","Discovery of Small Ultra-short-period Planets Orbiting KG Dwarfs in Kepler Survey Using GPU Phase Folding and Deep Learning Detection System","Kaitlyn Wang, Jian Ge, Kevin Willis, Kevin Wang, Yinan Zhao","Earth and Planetary Astrophysics (astro-ph.EP)","Since the discovery of the first hot Jupiter orbiting a solar-type star, 51 Peg, in 1995, more than 4000 exoplanets have been identified using various observational techniques. The formation process of these sub-Earths remains elusive, and acquiring additional samples is essential for investigating this unique population. In our study, we employ a novel GPU Phase Folding algorithm combined with a Convolutional Neural Network, termed the GPFC method, on Kepler photometry data. This method enhances the transit search speed significantly over the traditional Box-fitting Least Squares method, allowing a complete search of the known KOI photometry data within hours using a commercial GPU card. To date, we have identified five promising sub-Earth short-period candidates: K00446.c, K01821.b, K01522.c, K03404.b, and K04978.b. A closer analysis reveals the following characteristics: K00446.c orbits a K dwarf on a 0.645091-day period. With a radius of $0.461R_\oplus$, it ranks as the second smallest USP discovered to date. K01821.b is a sub-Earth with a radius of $0.648R_\oplus$, orbiting a G dwarf over a 0.91978-day period. It is the second smallest USP among all confirmed USPs orbiting G dwarfs in the NASA Archive. K01522.c has a radius of $0.704 R_\oplus$ and completes an orbit around a Sun-like G dwarf in 0.64672 days; K03404.b, with a radius of $0.738 R_\oplus$, orbits a G dwarf on a 0.68074-day period; and K04978.b, with its planetary radius of $0.912 R_\oplus$, orbits a G dwarf, completing an orbit every 0.94197 days. Three of our finds, K01821.b, K01522.c and K03404.b, rank as the smallest planets among all confirmed USPs orbiting G dwarfs in the Kepler dataset. The discovery of these small exoplanets underscores the promising capability of the GPFC method for searching for small, new transiting exoplanets in photometry data from Kepler, TESS, and future space transit missions.","Thu, 28 Dec 2023 22:12:54 UTC (22,997 KB)"
"46","A refinement of Kelly's lemma for graph reconstruction for counting rooted subgraphs","Deisiane Lopes Gonçalves, Bhalchandra D. Thatte","Combinatorics (math.CO)","Kelly's lemma is a basic result on graph reconstruction. It states that given the deck of a graph $G$ on $n$ vertices, and a graph $F$ on fewer than $n$ vertices, we can count the number of subgraphs of $G$ that are isomorphic to $F$. Moreover, for a given card $G-v$ in the deck, we can count the number of subgraphs of $G$ that are isomorphic to $F$ and that contain $v$. We consider the problem of refining the lemma to count rooted subgraphs such that the root vertex coincides the deleted vertex. We show that such counting is not possible in general, but a multiset of rooted subgraphs of a fixed height $k$ can be counted if $G$ has radius more than $k$. We also prove a similar result for the edge reconstruction problem.","Thu, 28 Dec 2023 13:47:11 UTC (9 KB)"
"47","Heavy-Traffic Optimal Size- and State-Aware Dispatching","Runhan Xie, Isaac Grosof, Ziv Scully","Performance (cs.PF)","Dispatching systems, where arriving jobs are immediately assigned to one of multiple queues, are ubiquitous in computer systems and service systems. A natural and practically relevant model is one in which each queue serves jobs in FCFS (First-Come First-Served) order. We consider the case where the dispatcher is size-aware, meaning it learns the size (i.e. service time) of each job as it arrives; and state-aware, meaning it always knows the amount of work (i.e. total remaining service time) at each queue. While size- and state-aware dispatching to FCFS queues has been extensively studied, little is known about optimal dispatching for the objective of minimizing mean delay. A major obstacle is that no nontrivial lower bound on mean delay is known, even in heavy traffic (i.e. the limit as load approaches capacity). This makes it difficult to prove that any given policy is optimal, or even heavy-traffic optimal. In this work, we propose the first size- and state-aware dispatching policy that provably minimizes mean delay in heavy traffic. Our policy, called CARD (Controlled Asymmetry Reduces Delay), keeps all but one of the queues short, then routes as few jobs as possible to the one long queue. We prove an upper bound on CARD's mean delay, and we prove the first nontrivial lower bound on the mean delay of any size- and state-aware dispatching policy. Both results apply to any number of servers. Our bounds match in heavy traffic, implying CARD's heavy-traffic optimality. In particular, CARD's heavy-traffic performance improves upon that of LWL (Least Work Left), SITA (Size Interval Task Assignment), and other policies from the literature whose heavy-traffic performance is known.","Wed, 27 Dec 2023 02:17:19 UTC (169 KB)[v2] Mon, 29 Jan 2024 00:49:50 UTC (353 KB)"
"48","Short-lived High-volume Multi-A(rmed)/B(andits) Testing","Su Jia, Andrew Li, R. Ravi, Nishant Oli, Paul Duff, Ian Anderson","Machine Learning (cs.LG)","Modern platforms leverage randomized experiments to make informed decisions from a given set of items (``treatments''). As a particularly challenging scenario, these items may (i) arrive in high volume, with thousands of new items being released per hour, and (ii) have short lifetime, say, due to the item's transient nature or underlying non-stationarity that impels the platform to perceive the same item as distinct copies over time. Thus motivated, we study a Bayesian multiple-play bandit problem that encapsulates the key features of the multivariate testing (or ``multi-A/B testing'') problem with a high volume of short-lived arms. In each round, a set of $k$ arms arrive, each available for $w$ rounds. Without knowing the mean reward for each arm, the learner selects a multiset of $n$ arms and immediately observes their realized rewards. We aim to minimize the loss due to not knowing the mean rewards, averaged over instances generated from a given prior distribution. We show that when $k = O(n^\rho)$ for some constant $\rho>0$, our proposed policy has $\tilde O(n^{-\min \{\rho, \frac 12 (1+\frac 1w)^{-1}\}})$ loss on a sufficiently large class of prior distributions. We complement this result by showing that every policy suffers $\Omega (n^{-\min \{\rho, \frac 12\}})$ loss on the same class of distributions. We further validate the effectiveness of our policy through a large-scale field experiment on {\em Glance}, a content-card-serving platform that faces exactly the above challenge. A simple variant of our policy outperforms the platform's current recommender by 4.32\% in total duration and 7.48\% in total number of click-throughs.","Sat, 23 Dec 2023 21:38:35 UTC (8,330 KB)"
"49","Reconstruction of the Ranks of the Nonextremal Cards and of Ordered Sets with a Minmax Pair of Pseudo-Similar Points","Bernd S. W. Schröder","Combinatorics (math.CO)","For every ordered set, we reconstruct the deck obtained by removal of the elements of rank r that are neither minimal nor maximal. Consequently, we also reconstruct the deck obtained by removal of the extremal, that is, minimal or maximal, elements. Finally, we reconstruct the ordered sets with a minmax pair of pseudo-similar points.","Sat, 23 Dec 2023 02:13:28 UTC (28 KB)[v2] Mon, 29 Jan 2024 17:06:33 UTC (28 KB)"
"50","The State of Documentation Practices of Third-party Machine Learning Models and Datasets","Ernesto Lang Oreamuno, Rohan Faiyaz Khan, Abdul Ali Bangash, Catherine Stinson, Bram Adams","Software Engineering (cs.SE)","Model stores offer third-party ML models and datasets for easy project integration, minimizing coding efforts. One might hope to find detailed specifications of these models and datasets in the documentation, leveraging documentation standards such as model and dataset cards. In this study, we use statistical analysis and hybrid card sorting to assess the state of the practice of documenting model cards and dataset cards in one of the largest model stores in use today--Hugging Face (HF). Our findings show that only 21,902 models (39.62\%) and 1,925 datasets (28.48\%) have documentation. Furthermore, we observe inconsistency in ethics and transparency-related documentation for ML models and datasets.","Fri, 22 Dec 2023 20:45:52 UTC (1,758 KB)"
"51","Open-Set: ID Card Presentation Attack Detection using Neural Transfer Style","Reuben Markham, Juan M. Espin, Mario Nieto-Hidalgo, Juan E. Tapia","Computer Vision and Pattern Recognition (cs.CV)","The accurate detection of ID card Presentation Attacks (PA) is becoming increasingly important due to the rising number of online/remote services that require the presentation of digital photographs of ID cards for digital onboarding or authentication. Furthermore, cybercriminals are continuously searching for innovative ways to fool authentication systems to gain unauthorized access to these services. Although advances in neural network design and training have pushed image classification to the state of the art, one of the main challenges faced by the development of fraud detection systems is the curation of representative datasets for training and evaluation. The handcrafted creation of representative presentation attack samples often requires expertise and is very time-consuming, thus an automatic process of obtaining high-quality data is highly desirable. This work explores ID card Presentation Attack Instruments (PAI) in order to improve the generation of samples with four Generative Adversarial Networks (GANs) based image translation models and analyses the effectiveness of the generated data for training fraud detection systems. Using open-source data, we show that synthetic attack presentations are an adequate complement for additional real attack presentations, where we obtain an EER performance increase of 0.63% points for print attacks and a loss of 0.29% for screen capture attacks.","Thu, 21 Dec 2023 16:28:08 UTC (30,880 KB)"
"52","Comparative Evaluation of Anomaly Detection Methods for Fraud Detection in Online Credit Card Payments","Hugo Thimonier, Fabrice Popineau, Arpad Rimmel, Bich-Liên Doan, Fabrice Daniel","Machine Learning (cs.LG)","This study explores the application of anomaly detection (AD) methods in imbalanced learning tasks, focusing on fraud detection using real online credit card payment data. We assess the performance of several recent AD methods and compare their effectiveness against standard supervised learning methods. Offering evidence of distribution shift within our dataset, we analyze its impact on the tested models' performances. Our findings reveal that LightGBM exhibits significantly superior performance across all evaluated metrics but suffers more from distribution shifts than AD methods. Furthermore, our investigation reveals that LightGBM also captures the majority of frauds detected by AD methods. This observation challenges the potential benefits of ensemble methods to combine supervised, and AD approaches to enhance performance. In summary, this research provides practical insights into the utility of these techniques in real-world scenarios, showing LightGBM's superiority in fraud detection while highlighting challenges related to distribution shifts.","Thu, 21 Dec 2023 14:42:42 UTC (5,903 KB)"
"53","Integration of Robotics, Computer Vision, and Algorithm Design: A Chinese Poker Self-Playing Robot","Kuan-Huang Yu","Robotics (cs.RO)","This paper presents Chinese Poker Self-Playing Robot, an integrated system enabling a TM5-900 robotic arm to independently play the four-person card game Chinese poker. The robot uses a custom sucker mechanism to pick up and play cards. An object detection model based on YOLOv5 is utilized to recognize the suit and number of 13 cards dealt to the robot. A greedy algorithm is developed to divide the 13 cards into optimal hands of 3, 5, and 5 cards to play. Experiments demonstrate that the robot can successfully obtain the cards, identify them using computer vision, strategically select hands to play using the algorithm, and physically play the selected cards in the game. The system showcases effective integration of mechanical design, computer vision, algorithm design, and robotic control to accomplish the complex task of independently playing cards.","Tue, 28 Nov 2023 06:53:34 UTC (1,526 KB)"
"54","YOLO-OB: An improved anchor-free real-time multiscale colon polyp detector in colonoscopy","Xiao Yang, Enmin Song, Guangzhi Ma, Yunfeng Zhu, Dongming Yu, Bowen Ding, Xianyuan Wang","Computer Vision and Pattern Recognition (cs.CV)","Colon cancer is expected to become the second leading cause of cancer death in the United States in 2023. Although colonoscopy is one of the most effective methods for early prevention of colon cancer, up to 30% of polyps may be missed by endoscopists, thereby increasing patients' risk of developing colon cancer. Though deep neural networks have been proven to be an effective means of enhancing the detection rate of polyps. However, the variation of polyp size brings the following problems: (1) it is difficult to design an efficient and sufficient multi-scale feature fusion structure; (2) matching polyps of different sizes with fixed-size anchor boxes is a hard challenge. These problems reduce the performance of polyp detection and also lower the model's training and detection efficiency. To address these challenges, this paper proposes a new model called YOLO-OB. Specifically, we developed a bidirectional multiscale feature fusion structure, BiSPFPN, which could enhance the feature fusion capability across different depths of a CNN. We employed the ObjectBox detection head, which used a center-based anchor-free box regression strategy that could detect polyps of different sizes on feature maps of any scale. Experiments on the public dataset SUN and the self-collected colon polyp dataset Union demonstrated that the proposed model significantly improved various performance metrics of polyp detection, especially the recall rate. Compared to the state-of-the-art results on the public dataset SUN, the proposed method achieved a 6.73% increase on recall rate from 91.5% to 98.23%. Furthermore, our YOLO-OB was able to achieve real-time polyp detection at a speed of 39 frames per second using a RTX3090 graphics card. The implementation of this paper can be found here: this https URL.","Thu, 14 Dec 2023 03:17:52 UTC (777 KB)"
"55","FULL-W2V: Fully Exploiting Data Reuse for W2V on GPU-Accelerated Systems","Thomas Randall, Tyler Allen, Rong Ge","Machine Learning (cs.LG)","Word2Vec remains one of the highly-impactful innovations in the field of Natural Language Processing (NLP) that represents latent grammatical and syntactical information in human text with dense vectors in a low dimension. Word2Vec has high computational cost due to the algorithm's inherent sequentiality, intensive memory accesses, and the large vocabularies it represents. While prior studies have investigated technologies to explore parallelism and improve memory system performance, they struggle to effectively gain throughput on powerful GPUs. We identify memory data access and latency as the primary bottleneck in prior works on GPUs, which prevents highly optimized kernels from attaining the architecture's peak performance. We present a novel algorithm, FULL-W2V, which maximally exploits the opportunities for data reuse in the W2V algorithm and leverages GPU architecture and resources to reduce access to low memory levels and improve temporal locality. FULL-W2V is capable of reducing accesses to GPU global memory significantly, e.g., by more than 89\%, compared to prior state-of-the-art GPU implementations, resulting in significant performance improvement that scales across successive hardware generations. Our prototype implementation achieves 2.97X speedup when ported from Nvidia Pascal P100 to Volta V100 cards, and outperforms the state-of-the-art by 5.72X on V100 cards with the same embedding quality. In-depth analysis indicates that the reduction of memory accesses through register and shared memory caching and high-throughput shared memory reduction leads to a significantly improved arithmetic intensity. FULL-W2V can potentially benefit many applications in NLP and other domains.","Tue, 12 Dec 2023 21:22:07 UTC (1,033 KB)"
"56","Hierarchical Classification of Financial Transactions Through Context-Fusion of Transformer-based Embeddings and Taxonomy-aware Attention Layer","Antonio J. G. Busson, Rafael Rocha, Rennan Gaio, Rafael Miceli, Ivan Pereira, Daniel de S. Moraes, Sérgio Colcher, Alvaro Veiga, Bruno Rizzi, Francisco Evangelista, Leandro Santos, Fellipe Marques, Marcos Rabaioli, Diego Feldberg, Debora Mattos, João Pasqua, Diogo Dias","Machine Learning (cs.LG)","This work proposes the Two-headed DragoNet, a Transformer-based model for hierarchical multi-label classification of financial transactions. Our model is based on a stack of Transformers encoder layers that generate contextual embeddings from two short textual descriptors (merchant name and business activity), followed by a Context Fusion layer and two output heads that classify transactions according to a hierarchical two-level taxonomy (macro and micro categories). Finally, our proposed Taxonomy-aware Attention Layer corrects predictions that break categorical hierarchy rules defined in the given taxonomy. Our proposal outperforms classical machine learning methods in experiments of macro-category classification by achieving an F1-score of 93\% on a card dataset and 95% on a current account dataset.","Tue, 12 Dec 2023 20:51:41 UTC (2,267 KB)"
"57","Hybrid-Rendering Techniques in GPU","Pedro Granja, João Pereira","Graphics (cs.GR)","Ray tracing has long been the holy grail of real time rendering. This technique, commonly used for photo realism, simulates the physical behavior of light, at the cost of being computationally heavy. With the introduction of Nvidia RTX graphic card family, which provides hardware support for ray tracing, this technique started to look like a reality for real time. However, the same problems that afflicted the usage of this technique remain, and even with specialized hardware it is still extremely expensive. To account for these drawbacks, researchers and developers pair this technique with rasterization and denoising. This results in a hybrid system that tries to join the best of both worlds, having both photo realistic quality and real time performance. In this work we intend on further exploring hybrid render systems, offering a review of the state of the art with a special focus on real time ray tracing and our own hybrid implementation with photo realistic quality and real time performance (>30 fps), implemented using the Vulkan API. In this project, we highlight the detailed analysis of the impacts of History Rectification (Variance Color Clamping) on the temporal filter component of the denoising system and how to overcome the introduced artifacts. Additionally, we also highlight the analysis of the introduction of a separable blur on the spatial filter and the introduction of Reinhard Tone Mapping prior to denoising, consequently improving this procedure.","Mon, 11 Dec 2023 20:38:17 UTC (756 KB)"
"58","A Primer on RecoNIC: RDMA-enabled Compute Offloading on SmartNIC","Guanwen Zhong, Aditya Kolekar, Burin Amornpaisannon, Inho Choi, Haris Javaid, Mario Baldi","Distributed, Parallel, and Cluster Computing (cs.DC)","Today's data centers consist of thousands of network-connected hosts, each with CPUs and accelerators such as GPUs and FPGAs. These hosts also contain network interface cards (NICs), operating at speeds of 100Gb/s or higher, that are used to communicate with each other. We propose RecoNIC, an FPGA-based RDMA-enabled SmartNIC platform that is designed for compute acceleration while minimizing the overhead associated with data copies (in CPU-centric accelerator systems) by bringing network data as close to computation as possible. Since RDMA is the defacto transport-layer protocol for improved communication in data center workloads, RecoNIC includes an RDMA offload engine for high throughput and low latency data transfers. Developers have the flexibility to design their accelerators using RTL, HLS or Vitis Networking P4 within the RecoNIC's programmable compute blocks. These compute blocks can access host memory as well as memory in remote peers through the RDMA offload engine. Furthermore, the RDMA offload engine is shared by both the host and compute blocks, which makes RecoNIC a very flexible platform. Lastly, we have open-sourced RecoNIC for the research community to enable experimentation with RDMA-based applications and use-cases.","Mon, 11 Dec 2023 08:41:50 UTC (838 KB)"
"59","SYSFLOW: Efficient Execution Platform for IoT Devices","Jun Lu, Zhenya Ma, Yinggang Gao, Ju Ren, Yaoxue Zhang","Networking and Internet Architecture (cs.NI)","Traditional executable delivery models pose challenges for IoT devices with limited storage, necessitating the download of complete executables and dependencies. Network solutions like NFS, designed for data files, encounter high IO overhead for irregular access patterns. This paper introduces SYSFLOW, a lightweight network-based executable delivery system for IoT. SYSFLOW delivers on-demand, redirecting local disk IO to the server through optimized network IO. To optimize cache hit rates, SYSFLOW employs server-side action-based prefetching, reducing latency by 45.1% to 75.8% compared to native Linux filesystems on SD cards. In wired environments, SYSFLOW's latency is up to 67.7% lower than NFS. In wireless scenarios, SYSFLOW performs 22.9% worse than Linux, comparable with Linux and outperforming NFS by up to 60.7%. While SYSFLOW's power consumption may be 6.7% higher than NFS, it offers energy savings due to lower processing time.","Fri, 8 Dec 2023 07:13:03 UTC (18,209 KB)"
"60","Stochastic modelling of football matches","Luiz Fernando G. N. Maia, Teemu Pennanen, Moacyr A. H. B. da Silva, Rodrigo S. Targino","Applications (stat.AP)","This paper develops a general framework for stochastic modeling of goals and other events in football (soccer) matches. The events are modelled as Cox processes (doubly stochastic Poisson processes) where the event intensities may depend on all the modeled events as well as external factors. The model has a strictly concave log-likelihood function which facilitates its fitting to observed data. Besides event times, the model describes the random lengths of stoppage times which can have a strong influence on the final score of a match. The model is illustrated on eight years of data from Campeonato Brasileiro de Futebol Série A. We find that dynamic regressors significantly improve the in-game predictive power of the model. In particular, a) when a team receives a red card, its goal intensity decreases more than 30%; b) the goal rate of a team increases by 10% if it is losing by one goal and by 20% if its losing by two goals; and c) when the goal difference at the end of the second half is less than or equal to one, the stoppage time is on average more than one minute longer than in matches with a difference of two goals.","Thu, 7 Dec 2023 14:59:04 UTC (2,153 KB)"
"61","The BigCode Project Governance Card","BigCode collaboration: Sean Hughes, Harm de Vries, Jennifer Robinson, Carlos Muñoz Ferrandis, Loubna Ben Allal, Leandro von Werra, Jennifer Ding, Sebastien Paquet, Yacine Jernite","Computers and Society (cs.CY)","This document serves as an overview of the different mechanisms and areas of governance in the BigCode project. It aims to support transparency by providing relevant information about choices that were made during the project to the broader public, and to serve as an example of intentional governance of an open research project that future endeavors can leverage to shape their own approach. The first section, Project Structure, covers the project organization, its stated goals and values, its internal decision processes, and its funding and resources. The second section, Data and Model Governance, covers decisions relating to the questions of data subject consent, privacy, and model release.","Wed, 6 Dec 2023 19:37:08 UTC (37 KB)"
"62","Holmes: Towards Distributed Training Across Clusters with Heterogeneous NIC Environment","Fei Yang, Shuang Peng, Ning Sun, Fangyu Wang, Ke Tan, Fu Wu, Jiezhong Qiu, Aimin Pan","Computation and Language (cs.CL)","Large language models (LLMs) such as GPT-3, OPT, and LLaMA have demonstrated remarkable accuracy in a wide range of tasks. However, training these models can incur significant expenses, often requiring tens of thousands of GPUs for months of continuous operation. Typically, this training is carried out in specialized GPU clusters equipped with homogeneous high-speed Remote Direct Memory Access (RDMA) network interface cards (NICs). The acquisition and maintenance of such dedicated clusters is challenging. Current LLM training frameworks, like Megatron-LM and Megatron-DeepSpeed, focus primarily on optimizing training within homogeneous cluster settings. In this paper, we introduce Holmes, a training framework for LLMs that employs thoughtfully crafted data and model parallelism strategies over the heterogeneous NIC environment. Our primary technical contribution lies in a novel scheduling method that intelligently allocates distinct computational tasklets in LLM training to specific groups of GPU devices based on the characteristics of their connected NICs. Furthermore, our proposed framework, utilizing pipeline parallel techniques, demonstrates scalability to multiple GPU clusters, even in scenarios without high-speed interconnects between nodes in distinct clusters. We conducted comprehensive experiments that involved various scenarios in the heterogeneous NIC environment. In most cases, our framework achieves performance levels close to those achievable with homogeneous RDMA-capable networks (InfiniBand or RoCE), significantly exceeding training efficiency within the pure Ethernet environment. Additionally, we verified that our framework outperforms other mainstream LLM frameworks under heterogeneous NIC environment in terms of training efficiency and can be seamlessly integrated with them.","Wed, 6 Dec 2023 15:27:26 UTC (622 KB)[v2] Thu, 7 Dec 2023 09:26:07 UTC (850 KB)[v3] Mon, 11 Dec 2023 10:22:42 UTC (954 KB)"
"63","DanZero+: Dominating the GuanDan Game through Reinforcement Learning","Youpeng Zhao, Yudong Lu, Jian Zhao, Wengang Zhou, Houqiang Li","Artificial Intelligence (cs.AI)","The utilization of artificial intelligence (AI) in card games has been a well-explored subject within AI research for an extensive period. Recent advancements have propelled AI programs to showcase expertise in intricate card games such as Mahjong, DouDizhu, and Texas Hold'em. In this work, we aim to develop an AI program for an exceptionally complex and popular card game called GuanDan. This game involves four players engaging in both competitive and cooperative play throughout a long process to upgrade their level, posing great challenges for AI due to its expansive state and action space, long episode length, and complex rules. Employing reinforcement learning techniques, specifically Deep Monte Carlo (DMC), and a distributed training framework, we first put forward an AI program named DanZero for this game. Evaluation against baseline AI programs based on heuristic rules highlights the outstanding performance of our bot. Besides, in order to further enhance the AI's capabilities, we apply policy-based reinforcement learning algorithm to GuanDan. To address the challenges arising from the huge action space, which will significantly impact the performance of policy-based algorithms, we adopt the pre-trained model to facilitate the training process and the achieved AI program manages to achieve a superior performance.","Tue, 5 Dec 2023 08:07:32 UTC (1,659 KB)"
"64","Co-Designed Superconducting Architecture for Lattice Surgery of Surface Codes with Quantum Interface Routing Card","Charles Guinn, Samuel Stein, Esin Tureci, Guus Avis, Chenxu Liu, Stefan Krastanov, Andrew A. Houck, Ang Li","Quantum Physics (quant-ph)","Facilitating the ability to achieve logical qubit error rates below physical qubit error rates, error correction is anticipated to play an important role in scaling quantum computers. While many algorithms require millions of physical qubits to be executed with error correction, current superconducting qubit systems contain only hundreds of physical qubits. One of the most promising codes on the superconducting qubit platform is the surface code, requiring a realistically attainable error threshold and the ability to perform universal fault-tolerant quantum computing with local operations via lattice surgery and magic state injection. Surface code architectures easily generalize to single-chip planar layouts, however space and control hardware constraints point to limits on the number of qubits that can fit on one chip. Additionally, the planar routing on single-chip architectures leads to serialization of commuting gates and strain on classical decoding caused by large ancilla patches. A distributed multi-chip architecture utilizing the surface code can potentially solve these problems if one can optimize inter-chip gates, manage collisions in networking between chips, and minimize routing hardware costs. We propose QuIRC, a superconducting Quantum Interface Routing Card for Lattice Surgery between surface code modules inside of a single dilution refrigerator. QuIRC improves scaling by allowing connection of many modules, increases ancilla connectivity of surface code lattices, and offers improved transpilation of Pauli-based surface code circuits. QuIRC employs in-situ Entangled Pair (EP) generation protocols for communication. We explore potential topological layouts of QuIRC based on superconducting hardware fabrication constraints, and demonstrate reductions in ancilla patch size by up to 77.8%, and in layer transpilation size by 51.9% when compared to the single-chip case.","Sat, 2 Dec 2023 23:23:55 UTC (561 KB)"
"65","CLIPC8: Face liveness detection algorithm based on image-text pairs and contrastive learning","Xu Liu, Shu Zhou, Yurong Song, Wenzhe Luo, Xin Zhang","Computer Vision and Pattern Recognition (cs.CV)","Face recognition technology is widely used in the financial field, and various types of liveness attack behaviors need to be addressed. Existing liveness detection algorithms are trained on specific training datasets and tested on testing datasets, but their performance and robustness in transferring to unseen datasets are relatively poor. To tackle this issue, we propose a face liveness detection method based on image-text pairs and contrastive learning, dividing liveness attack problems in the financial field into eight categories and using text information to describe the images of these eight types of attacks. The text encoder and image encoder are used to extract feature vector representations for the classification description text and face images, respectively. By maximizing the similarity of positive samples and minimizing the similarity of negative samples, the model learns shared representations between images and texts. The proposed method is capable of effectively detecting specific liveness attack behaviors in certain scenarios, such as those occurring in dark environments or involving the tampering of ID card photos. Additionally, it is also effective in detecting traditional liveness attack methods, such as printing photo attacks and screen remake attacks. The zero-shot capabilities of face liveness detection on five public datasets, including NUAA, CASIA-FASD, Replay-Attack, OULU-NPU and MSU-MFSD also reaches the level of commercial algorithms. The detection capability of proposed algorithm was verified on 5 types of testing datasets, and the results show that the method outperformed commercial algorithms, and the detection rates reached 100% on multiple datasets. Demonstrating the effectiveness and robustness of introducing image-text pairs and contrastive learning into liveness detection tasks as proposed in this paper.","Wed, 29 Nov 2023 12:21:42 UTC (6,709 KB)"
"66","Two-Step Reinforcement Learning for Multistage Strategy Card Game","Konrad Godlewski, Bartosz Sawicki","Artificial Intelligence (cs.AI)","In the realm of artificial intelligence and card games, this study introduces a two-step reinforcement learning (RL) strategy tailored for ""The Lord of the Rings: The Card Game (LOTRCG),"" a complex multistage strategy card game. This research diverges from conventional RL methods by adopting a phased learning approach, beginning with a foundational learning stage in a simplified version of the game and subsequently progressing to the complete, intricate game environment. This methodology notably enhances the AI agent's adaptability and performance in the face of LOTRCG's unpredictable and challenging nature. The paper also explores a multi-agent system, where distinct RL agents are employed for various decision-making aspects of the game. This approach has demonstrated a remarkable improvement in game outcomes, with the RL agents achieving a winrate of 78.5% across a set of 10,000 random games.","Wed, 29 Nov 2023 01:31:21 UTC (2,972 KB)"
"67","Recognizing trees from incomplete decks","Gabriëlle Zwaneveld","Combinatorics (math.CO)","For a given graph, the unlabeled subgraphs $G-v$ are called the cards of $G$ and the deck of $G$ is the multiset $\{G-v: v \in V(G)\}$. Wendy Myrvold [Ars Combinatoria, 1989] showed that a non-connected graph and a connected graph both on $n$ vertices have at most $\lfloor \frac{n}{2} \rfloor +1$ cards in common and she found (infinite) families of trees and non-connected forests for which this upper bound is tight. Bowler, Brown, and Fenner [Journal of Graph Theory, 2010] conjectured that this bound is tight for $n \geq 44$. In this article, we prove this conjecture for sufficiently large $n$. The main result is that a tree $T$ and a unicyclic graph $G$ on $n$ vertices have at most $\lfloor \frac{n}{2} \rfloor+1$ common cards. Combined with Myrvold's work this shows that it can be determined whether a graph on $n$ vertices is a tree from any $\lfloor \frac{n}{2}\rfloor+2$ of its cards. Based on this theorem, it follows that any forest and non-forest also have at most $\lfloor \frac{n}{2} \rfloor +1$ common cards. Moreover, we have classified all except finitely many pairs for which this bound is strict. Furthermore, the main ideas of the proof for trees are used to show that the girth of a graph on $n$ vertices can be determined based on any $\frac{2n}{3} +1$ of its cards. Lastly, we show that any $\frac{5n}{6} +2$ cards determine whether a graph is bipartite.","Tue, 28 Nov 2023 10:26:27 UTC (387 KB)[v2] Mon, 18 Dec 2023 10:49:49 UTC (387 KB)"
"68","ET3D: Efficient Text-to-3D Generation via Multi-View Distillation","Yiming Chen, Zhiqi Li, Peidong Liu","Computer Vision and Pattern Recognition (cs.CV)","Recent breakthroughs in text-to-image generation has shown encouraging results via large generative models. Due to the scarcity of 3D assets, it is hardly to transfer the success of text-to-image generation to that of text-to-3D generation. Existing text-to-3D generation methods usually adopt the paradigm of DreamFusion, which conducts per-asset optimization by distilling a pretrained text-to-image diffusion model. The generation speed usually ranges from several minutes to tens of minutes per 3D asset, which degrades the user experience and also imposes a burden to the service providers due to the high computational budget. In this work, we present an efficient text-to-3D generation method, which requires only around 8 $ms$ to generate a 3D asset given the text prompt on a consumer graphic card. The main insight is that we exploit the images generated by a large pre-trained text-to-image diffusion model, to supervise the training of a text conditioned 3D generative adversarial network. Once the network is trained, we are able to efficiently generate a 3D asset via a single forward pass. Our method requires no 3D training data and provides an alternative approach for efficient text-to-3D generation by distilling pre-trained image diffusion models.","Mon, 27 Nov 2023 06:14:23 UTC (12,054 KB)"
"69","History Filtering in Imperfect Information Games: Algorithms and Complexity","Christopher Solinas, Douglas Rebstock, Nathan R. Sturtevant, Michael Buro","Computer Science and Game Theory (cs.GT)","Historically applied exclusively to perfect information games, depth-limited search with value functions has been key to recent advances in AI for imperfect information games. Most prominent approaches with strong theoretical guarantees require subgame decomposition - a process in which a subgame is computed from public information and player beliefs. However, subgame decomposition can itself require non-trivial computations, and its tractability depends on the existence of efficient algorithms for either full enumeration or generation of the histories that form the root of the subgame. Despite this, no formal analysis of the tractability of such computations has been established in prior work, and application domains have often consisted of games, such as poker, for which enumeration is trivial on modern hardware. Applying these ideas to more complex domains requires understanding their cost. In this work, we introduce and analyze the computational aspects and tractability of filtering histories for subgame decomposition. We show that constructing a single history from the root of the subgame is generally intractable, and then provide a necessary and sufficient condition for efficient enumeration. We also introduce a novel Markov Chain Monte Carlo-based generation algorithm for trick-taking card games - a domain where enumeration is often prohibitively expensive. Our experiments demonstrate its improved scalability in the trick-taking card game Oh Hell. These contributions clarify when and how depth-limited search via subgame decomposition can be an effective tool for sequential decision-making in imperfect information settings.","Fri, 24 Nov 2023 18:34:36 UTC (2,098 KB)"
"70","Analyzing the Evolution and Maintenance of ML Models on Hugging Face","Joel Castaño, Silverio Martínez-Fernández, Xavier Franch, Justus Bogner","Software Engineering (cs.SE)","Hugging Face (HF) has established itself as a crucial platform for the development and sharing of machine learning (ML) models. This repository mining study, which delves into more than 380,000 models using data gathered via the HF Hub API, aims to explore the community engagement, evolution, and maintenance around models hosted on HF, aspects that have yet to be comprehensively explored in the literature. We first examine the overall growth and popularity of HF, uncovering trends in ML domains, framework usage, authors grouping and the evolution of tags and datasets used. Through text analysis of model card descriptions, we also seek to identify prevalent themes and insights within the developer community. Our investigation further extends to the maintenance aspects of models, where we evaluate the maintenance status of ML models, classify commit messages into various categories (corrective, perfective, and adaptive), analyze the evolution across development stages of commits metrics and introduce a new classification system that estimates the maintenance status of models based on multiple attributes. This study aims to provide valuable insights about ML model maintenance and evolution that could inform future model development strategies on platforms like HF.","Wed, 22 Nov 2023 13:20:25 UTC (2,257 KB)[v2] Mon, 5 Feb 2024 13:37:21 UTC (2,262 KB)"
"71","A PSO Based Method to Generate Actionable Counterfactuals for High Dimensional Data","Shashank Shekhar, Asif Salim, Adesh Bansode, Vivaswan Jinturkar, Anirudha Nayak","Artificial Intelligence (cs.AI)","Counterfactual explanations (CFE) are methods that explain a machine learning model by giving an alternate class prediction of a data point with some minimal changes in its features. It helps the users to identify their data attributes that caused an undesirable prediction like a loan or credit card rejection. We describe an efficient and an actionable counterfactual (CF) generation method based on particle swarm optimization (PSO). We propose a simple objective function for the optimization of the instance-centric CF generation problem. The PSO brings in a lot of flexibility in terms of carrying out multi-objective optimization in large dimensions, capability for multiple CF generation, and setting box constraints or immutability of data attributes. An algorithm is proposed that incorporates these features and it enables greater control over the proximity and sparsity properties over the generated CFs. The proposed algorithm is evaluated with a set of action-ability metrics in real-world datasets, and the results were superior compared to that of the state-of-the-arts.","Sat, 30 Sep 2023 18:08:00 UTC (18 KB)[v2] Thu, 30 Nov 2023 06:12:38 UTC (427 KB)"
"72","Benchmarking bias: Expanding clinical AI model card to incorporate bias reporting of social and non-social factors","Carolina A. M. Heming, Mohamed Abdalla, Monish Ahluwalia, Linglin Zhang, Hari Trivedi, MinJae Woo, Benjamin Fine, Judy Wawira Gichoya, Leo Anthony Celi, Laleh Seyyed-Kalantari","Computer Vision and Pattern Recognition (cs.CV)","Clinical AI model reporting cards should be expanded to incorporate a broad bias reporting of both social and non-social factors. Non-social factors consider the role of other factors, such as disease dependent, anatomic, or instrument factors on AI model bias, which are essential to ensure safe deployment.","Tue, 21 Nov 2023 12:12:19 UTC (748 KB)"
"73","Unveiling the Power of Self-Attention for Shipping Cost Prediction: The Rate Card Transformer","P Aditya Sreekar, Sahil Verma, Varun Madhavan, Abhishek Persad","Machine Learning (cs.LG)","Amazon ships billions of packages to its customers annually within the United States. Shipping cost of these packages are used on the day of shipping (day 0) to estimate profitability of sales. Downstream systems utilize these days 0 profitability estimates to make financial decisions, such as pricing strategies and delisting loss-making products. However, obtaining accurate shipping cost estimates on day 0 is complex for reasons like delay in carrier invoicing or fixed cost components getting recorded at monthly cadence. Inaccurate shipping cost estimates can lead to bad decision, such as pricing items too low or high, or promoting the wrong product to the customers. Current solutions for estimating shipping costs on day 0 rely on tree-based models that require extensive manual engineering efforts. In this study, we propose a novel architecture called the Rate Card Transformer (RCT) that uses self-attention to encode all package shipping information such as package attributes, carrier information and route plan. Unlike other transformer-based tabular models, RCT has the ability to encode a variable list of one-to-many relations of a shipment, allowing it to capture more information about a shipment. For example, RCT can encode properties of all products in a package. Our results demonstrate that cost predictions made by the RCT have 28.82% less error compared to tree-based GBDT model. Moreover, the RCT outperforms the state-of-the-art transformer-based tabular model, FTTransformer, by 6.08%. We also illustrate that the RCT learns a generalized manifold of the rate card that can improve the performance of tree-based models.","Mon, 20 Nov 2023 11:48:50 UTC (172 KB)"
"74","Assessing AI Impact Assessments: A Classroom Study","Nari Johnson, Hoda Heidari","Computers and Society (cs.CY)","Artificial Intelligence Impact Assessments (""AIIAs""), a family of tools that provide structured processes to imagine the possible impacts of a proposed AI system, have become an increasingly popular proposal to govern AI systems. Recent efforts from government or private-sector organizations have proposed many diverse instantiations of AIIAs, which take a variety of forms ranging from open-ended questionnaires to graded score-cards. However, to date that has been limited evaluation of existing AIIA instruments. We conduct a classroom study (N = 38) at a large research-intensive university (R1) in an elective course focused on the societal and ethical implications of AI. We assign students to different organizational roles (for example, an ML scientist or product manager) and ask participant teams to complete one of three existing AI impact assessments for one of two imagined generative AI systems. In our thematic analysis of participants' responses to pre- and post-activity questionnaires, we find preliminary evidence that impact assessments can influence participants' perceptions of the potential risks of generative AI systems, and the level of responsibility held by AI experts in addressing potential harm. We also discover a consistent set of limitations shared by several existing AIIA instruments, which we group into concerns about their format and content, as well as the feasibility and effectiveness of the activity in foreseeing and mitigating potential harms. Drawing on the findings of this study, we provide recommendations for future work on developing and validating AIIAs.","Sun, 19 Nov 2023 01:00:59 UTC (15,671 KB)"
"75","Text Sanitization Beyond Specific Domains: Zero-Shot Redaction & Substitution with Large Language Models","Federico Albanese, Daniel Ciolek, Nicolas D'Ippolito","Computation and Language (cs.CL)","In the context of information systems, text sanitization techniques are used to identify and remove sensitive data to comply with security and regulatory requirements. Even though many methods for privacy preservation have been proposed, most of them are focused on the detection of entities from specific domains (e.g., credit card numbers, social security numbers), lacking generality and requiring customization for each desirable domain. Moreover, removing words is, in general, a drastic measure, as it can degrade text coherence and contextual information. Less severe measures include substituting a word for a safe alternative, yet it can be challenging to automatically find meaningful substitutions. We present a zero-shot text sanitization technique that detects and substitutes potentially sensitive information using Large Language Models. Our evaluation shows that our method excels at protecting privacy while maintaining text coherence and contextual information, preserving data utility for downstream tasks.","Thu, 16 Nov 2023 18:42:37 UTC (24 KB)"
"76","Explaining Explanation: An Empirical Study on Explanation in Code Reviews","Ratnadira Widyasari, Ting Zhang, Abir Bouraffa, David Lo","Software Engineering (cs.SE)","Code review is an important process for quality assurance in software development. For an effective code review, the reviewers must explain their feedback to enable the authors of the code change to act on them. However, the explanation needs may differ among developers, who may require different types of explanations. It is therefore crucial to understand what kind of explanations reviewers usually use in code reviews. To the best of our knowledge, no study published to date has analyzed the types of explanations used in code review. In this study, we present the first analysis of explanations in useful code reviews. We extracted a set of code reviews based on their usefulness and labeled them based on whether they contained an explanation, a solution, or both a proposed solution and an explanation thereof. Based on our analysis, we found that a significant portion of the code review comments (46%) only include solutions without providing an explanation. We further investigated the remaining 54% of code review comments containing an explanation and conducted an open card sorting to categorize the reviewers' explanations. We distilled seven distinct categories of explanations based on the expression forms developers used. Then, we utilize large language models, specifically ChatGPT, to assist developers in getting a code review explanation that suits their preferences. Specifically, we created prompts to transform a code review explanation into a specific type of explanation. Our evaluation results show that ChatGPT correctly generated the specified type of explanation in 88/90 cases and that 89/90 of the cases have the correct explanation. Overall, our study provides insights into the types of explanations that developers use in code review and showcases how ChatGPT can be leveraged during the code review process to generate a specific type of explanation.","Wed, 15 Nov 2023 15:08:38 UTC (1,425 KB)"
"77","A Wi-Fi Signal-Based Human Activity Recognition Using High-Dimensional Factor Models","Junshuo Liu, Fuhai Wang, Zhe Li, Rujing Xiong, Tiebin Mi, Robert Caiming Qiu","Systems and Control (eess.SY)","Passive sensing techniques based on Wi-Fi signals have emerged as a promising technology in advanced wireless communication systems due to their widespread application and cost-effectiveness. However, the proliferation of low-cost Internet of Things (IoT) devices has led to dense network deployments, resulting in increased levels of noise and interference in Wi-Fi environments. This, in turn, leads to noisy and redundant Channel State Information (CSI) data. As a consequence, the accuracy of human activity recognition based on Wi-Fi signals is compromised. To address this issue, we propose a novel CSI data signal extraction method. We established a human activity recognition system based on the Intel 5300 network interface cards (NICs) and collected a dataset containing six categories of human activities. Using our approach, signals extracted from the CSI data serve as inputs to machine learning (ML) classification algorithms to evaluate classification performance. In comparison to ML methods based on Principal Component Analysis (PCA), our proposed High-Dimensional Factor Model (HDFM) method improves recognition accuracy by 6.8%.","Fri, 10 Nov 2023 08:09:51 UTC (680 KB)"
"78","Understanding the Difference between Office Presence and Co-presence in Team Member Interactions","Nils Brede Moe, Simen Ulsaker, Darja Smite, Jarle Moss Hildrum, Fehime Ceren Ay","Computers and Society (cs.CY)","Although the public health emergency related to the coronavirus disease 2019 (COVID-19) pandemic has officially ended, many software developers still work partly from home. Agile teams that coordinate their office time foster a sense of unity, collaboration, and cohesion among team members. In contrast, teams with limited co-presence may experience challenges in establishing psychological safety and developing a cohesive and inclusive team culture, potentially hindering effective communication, knowledge sharing, and trust building. Therefore, the effect of agile team members not being co-located daily must be investigated. We explore the co-presence patterns of 17 agile teams in a large agile telecommunications company whose employees work partly from home. Based on office access card data, we found significant variation in co-presence practices. Some teams exhibited a coordinated approach, ensuring team members are simultaneously present at the office. However, other teams demonstrated fragmented co-presence, with only small subgroups of members meeting in person and the remainder rarely interacting with their team members face-to-face. Thus, high average office presence in the team does not necessarily imply that team members meet often in person at the office. In contrast, non-coordinated teams may have both high average office presence and low frequency of in-person interactions among the members. Our results suggest that the promotion of mere office presence without coordinated co-presence is based on a false assumption that good average attendance levels guarantee frequent personal interactions. These findings carry important implications for research on long-term team dynamics and practice.","Sat, 23 Sep 2023 15:58:56 UTC (593 KB)"
"79","General-purpose machine-learned potential for 16 elemental metals and their alloys","Keke Song, Rui Zhao, Jiahui Liu, Yanzhou Wang, Eric Lindgren, Yong Wang, Shunda Chen, Ke Xu, Ting Liang, Penghua Ying, Nan Xu, Zhiqiang Zhao, Jiuyang Shi, Junjie Wang, Shuang Lyu, Zezhu Zeng, Shirong Liang, Haikuan Dong, Ligang Sun, Yue Chen, Zhuhua Zhang, Wanlin Guo, Ping Qian, Jian Sun, Paul Erhart, Tapio Ala-Nissila, Yanjing Su, Zheyong Fan","Materials Science (cond-mat.mtrl-sci)","Machine-learned potentials (MLPs) trained against quantum-mechanical reference data have demonstrated remarkable accuracy, surpassing empirical potentials. However, the absence of readily available general-purpose MLPs encompassing a broad spectrum of elements and their alloys hampers the applications of MLPs in materials science. In this study, we present a feasible approach for constructing a unified general-purpose MLP for numerous elements and showcase its capability by developing a model (UNEP-v1) for 16 elemental metals (Ag, Al, Au, Cr, Cu, Mg, Mo, Ni, Pb, Pd, Pt, Ta, Ti, V, W, Zr) and their diverse alloys. To achieve a complete representation of the chemical space, we demonstrate that employing 16 one-component and 120 two-component systems suffices, thereby avoiding the enumeration of all 65 535 possible combinations for training data generation. Furthermore, we illustrate that systems with more components can be adequately represented as interpolation points in the descriptor space. Our unified MLP exhibits superior performance across various physical properties as compared to the embedded-atom method potential, while maintaining computational efficiency. It achieves a remarkable computational speed of $1.5 \times 10^8$ atom step / second in molecular dynamics simulations using eight 80-gigabyte A100 graphics cards, enabling simulations up to 100 million atoms. We demonstrate the generality and high efficiency of the MLP in studying plasticity and primary radiation damage in the MoTaVW refractory high-entropy alloys, showcasing its potential in unraveling complex materials behavior. This work represents a significant leap towards the construction of a unified general-purpose MLP encompassing the periodic table, with profound implications for materials research and computational science.","Wed, 8 Nov 2023 14:59:27 UTC (11,354 KB)"
"80","Preliminary Design of Scalable Hardware Integrated Platform for LLRF Application","Lin Jiang, Jingjun Wen, Tao Xue, Xiaowei Guo, Haoyan Yang, Qiutong Pan, Jianmin Li, Yinong Liu, Liangjun Wei","Hardware Architecture (cs.AR)","In this paper, the SHIP4LLRF (Scalable Hardware Integrated Platform for LLRF) based on 6U VPX-standard was designed preliminarily, which includes 6U mother board and two HPC FPGA mezzanine cards (FMCs). The ADC and DAC FMC is based on ADS54J60 from TI and LTC2000Y-16 form ADI, respectively. The system mother board is based on Xilinx Kintex UltraScale KU060, which also features 64-bit DDR4 SDRAM, QSFP and USB3.0 interfaces. Each FMC connector is assigned 58 pairs of LVDS standard IOs and 8 pairs of GTH high-speed serial lanes. Besides, the mother board is equipped with the self-developed ZYNQBee2 module based on ZYNQ7010 for slow control such as EPICS. All ADC or DAC raw data in each SHIP4LLEF is compressed loss-less without triggering and transmitted to the process board. A scalar quantization method which is in development is used for lossless compression of ADC raw data, the process board will decompress the ADC data and perform a digital algorithm to measure the amplitude and phase of the high frequency signal. This de-sign is scalable for testing and upgradability, mean-while, the trigger-less data transmission enable this system participate in both local (rack-scale) and accelerator-wide communication networks.","Tue, 7 Nov 2023 09:44:46 UTC (767 KB)"
"81","Compact Data Structures for Network Telemetry","Shir Landau Feibish, Zaoxing Liu, Jennifer Rexford","Networking and Internet Architecture (cs.NI)","Collecting and analyzing of network traffic data (network telemetry) plays a critical role in managing modern networks. Network administrators analyze their traffic to troubleshoot performance and reliability problems, and to detect and block cyberattacks. However, conventional traffic-measurement techniques offer limited visibility into network conditions and rely on offline analysis. Fortunately, network devices such as switches and network interface cards, are increasingly programmable at the packet level, enabling flexible analysis of the traffic in place, as the packets fly by. However, to operate at high speed, these devices have limited memory and computational resources, leading to trade-offs between accuracy and overhead. In response, an exciting research area emerged, bringing ideas from compact data structures and streaming algorithms to bear on important networking telemetry applications and the unique characteristics of high-speed network devices. In this paper, we review the research on compact data structures for network telemetry and discuss promising directions for future research.","Sun, 5 Nov 2023 12:45:16 UTC (1,408 KB)"
"82","Lessons learned while developing the Serenity-S1 ATCA card","T. Mehner, L.E. Ardila-Perez, M. Balzer, G. Fedi, M. Fuchs, A. Howard, G. Iles, M. Loutit, S. Mansbridge, F. Palla, D. Parker, M. Pesaresi, A. Rose, M. Saleh, O. Sander, M. Schleicher, C. Strohman, D. Tcherniakhovski, T. Williams, J. Zhao","Instrumentation and Detectors (physics.ins-det)","The Serenity-S1 is a Xilinx Virtex Ultrascale+ based Advanced Telecommunications Computing Architecture (ATCA) processing blade that has been optimised for production. It incorporates many developments from the Serenity-A and Serenity-Z prototype cards and, where possible, adopts solutions being used across CERN. It also uses many new parts because commonly used parts have disappeared from the market during the semiconductor crisis, with only some returning. Improvements to simplify manufacture, the performance of new components, some of the more difficult aspects of procurement, the performance of production-grade Samtec 25\,Gb/s optical firefly parts, and issues with the rack cooling infrastructure are discussed.","Fri, 3 Nov 2023 20:16:53 UTC (3,106 KB)[v2] Thu, 14 Dec 2023 09:14:59 UTC (3,352 KB)"
"83","CMS ECAL VFE design, production and testing","W. Lustermann (1), D. Abadjiev (2), G. Dissertori (1), M. Dejardin (3), T. Gadek (1), L.T. Martin (2), K. Stachon (1) (on behalf of the CMS collaboration, (1) ETH Zurich, ETH Hönggerberg, Institute for Particle Physics and Astrophysics, Zurich, Switzerland, (2) Northeastern University, Department of Physics, Boston, MA, USA, (3) IRFU, CEA, Université Paris-Saclay, Gif Sur Yvette, France)","Instrumentation and Detectors (physics.ins-det)","Maintaining the required performance of the CMS electromagnetic calorimeter (ECAL) barrel at the High-Luminosity Large Hadron Collider (HL-LHC) requires the replacement of the entire on-detector electronics. 12240 new very front end (VFE) cards will amplify and digitize the signals of 62100 lead-tungstate crystals instrumented with avalanche photodiodes. The VFE cards host five channels of CATIA pre-amplifier ASICs followed by LiTE-DTU ASICs, which digitize signals with 160MS/s and 12bit resolution. We present the strategy and infrastructure developed for achieving the required reliability of less than 0.5% failing channels over the expected lifetime of 20 years. This includes the choice of standards, design for reliability and manufacturing, as well as factory acceptance tests, reception testing, environmental stress screening and calibration of the VFE cards.","Fri, 3 Nov 2023 16:32:40 UTC (607 KB)"
"84","Agent-based Modelling of Credit Card Promotions","Conor B. Hamill, Raad Khraishi, Simona Gherghel, Jerrard Lawrence, Salvatore Mercuri, Ramin Okhrati, Greig A. Cowan","Multiagent Systems (cs.MA)","Interest-free promotions are a prevalent strategy employed by credit card lenders to attract new customers, yet the research exploring their effects on both consumers and lenders remains relatively sparse. The process of selecting an optimal promotion strategy is intricate, involving the determination of an interest-free period duration and promotion-availability window, all within the context of competing offers, fluctuating market dynamics, and complex consumer behaviour. In this paper, we introduce an agent-based model that facilitates the exploration of various credit card promotions under diverse market scenarios. Our approach, distinct from previous agent-based models, concentrates on optimising promotion strategies and is calibrated using benchmarks from the UK credit card market from 2019 to 2020, with agent properties derived from historical distributions of the UK population from roughly the same period. We validate our model against stylised facts and time-series data, thereby demonstrating the value of this technique for investigating pricing strategies and understanding credit card customer behaviour. Our experiments reveal that, in the absence of competitor promotions, lender profit is maximised by an interest-free duration of approximately 12 months while market share is maximised by offering the longest duration possible. When competitors do not offer promotions, extended promotion availability windows yield maximum profit for lenders while also maximising market share. In the context of concurrent interest-free promotions, we identify that the optimal lender strategy entails offering a more competitive interest-free period and a rapid response to competing promotional offers. Notably, a delay of three months in responding to a rival promotion corresponds to a 2.4% relative decline in income.","Fri, 3 Nov 2023 13:21:21 UTC (1,828 KB)[v2] Thu, 23 Nov 2023 13:35:45 UTC (1,828 KB)"
"85","On Linear Complementary Pairs of Algebraic Geometry Codes over Finite Fields","Sanjit Bhowmick, Deepak Kumar Dalai, Sihem Mesnager","Information Theory (cs.IT)","Linear complementary dual (LCD) codes and linear complementary pairs (LCP) of codes have been proposed for new applications as countermeasures against side-channel attacks (SCA) and fault injection attacks (FIA) in the context of direct sum masking (DSM). The countermeasure against FIA may lead to a vulnerability for SCA when the whole algorithm needs to be masked (in environments like smart cards). This led to a variant of the LCD and LCP problems, where several results have been obtained intensively for LCD codes, but only partial results have been derived for LCP codes. Given the gap between the thin results and their particular importance, this paper aims to reduce this by further studying the LCP of codes in special code families and, precisely, the characterisation and construction mechanism of LCP codes of algebraic geometry codes over finite fields. Notably, we propose constructing explicit LCP of codes from elliptic curves. Besides, we also study the security parameters of the derived LCP of codes $(\mathcal{C}, \mathcal{D})$ (notably for cyclic codes), which are given by the minimum distances $d(\mathcal{C})$ and $d(\mathcal{D}^\perp)$. Further, we show that for LCP algebraic geometry codes $(\mathcal{C},\mathcal{D})$, the dual code $\mathcal{C}^\perp$ is equivalent to $\mathcal{D}$ under some specific conditions we exhibit. Finally, we investigate whether MDS LCP of algebraic geometry codes exist (MDS codes are among the most important in coding theory due to their theoretical significance and practical interests). Construction schemes for obtaining LCD codes from any algebraic curve were given in 2018 by Mesnager, Tang and Qi in [``Complementary dual algebraic geometry codes"", IEEE Trans. Inform Theory, vol. 64(4), 2390--3297, 2018]. To our knowledge, it is the first time LCP of algebraic geometry codes has been studied.","Thu, 2 Nov 2023 06:02:02 UTC (16 KB)"
"86","User Experiences with Third-Party SIM Cards and ID Registration in Kenya and Tanzania","Edith Luhanga (1), Karen Sowon (2), Lorrie Faith Cranor (2), Giulia Fanti (2), Conrad Tucker (2), Assane Gueye (1) ((1) Carnegie Mellon University - Africa, (2) Carnegie Mellon University)","Human-Computer Interaction (cs.HC)","Mobile money services in Sub-Saharan Africa (SSA) have increased access to financial services. To ensure proper identification of users, countries have put in place Know-Your-Customer (KYC) measures such as SIM registration using an official identification. However, half of the 850 million people without IDs globally live in SSA, and the use of SIM cards registered in another person's name (third-party SIM) is prevalent. In this study, we explore challenges that contribute to and arise from the use of third-party SIM cards. We interviewed 36 participants in Kenya and Tanzania. Our results highlight great strides in ID accessibility, but also highlight numerous institutional and social factors that contribute to the use of third-party SIM cards. While privacy concerns contribute to the use of third-party SIM cards, third-party SIM card users are exposed to significant security and privacy risks, including scams, financial loss, and wrongful arrest.","Wed, 1 Nov 2023 20:24:57 UTC (2,196 KB)"
"87","Closed Drafting as a Case Study for First-Principle Interpretability, Memory, and Generalizability in Deep Reinforcement Learning","Ryan Rezai, Jason Wang","Machine Learning (cs.LG)","Closed drafting or ""pick and pass"" is a popular game mechanic where each round players select a card or other playable element from their hand and pass the rest to the next player. In this paper, we establish first-principle methods for studying the interpretability, generalizability, and memory of Deep Q-Network (DQN) models playing closed drafting games. In particular, we use a popular family of closed drafting games called ""Sushi Go Party"", in which we achieve state-of-the-art performance. We fit decision rules to interpret the decision-making strategy of trained DRL agents by comparing them to the ranking preferences of different types of human players. As Sushi Go Party can be expressed as a set of closely-related games based on the set of cards in play, we quantify the generalizability of DRL models trained on various sets of cards, establishing a method to benchmark agent performance as a function of environment unfamiliarity. Using the explicitly calculable memory of other player's hands in closed drafting games, we create measures of the ability of DRL models to learn memory.","Tue, 31 Oct 2023 17:24:40 UTC (294 KB)[v2] Wed, 8 Nov 2023 17:56:38 UTC (334 KB)[v3] Fri, 17 Nov 2023 17:01:26 UTC (749 KB)"
"88","Evolutionary Tabletop Game Design: A Case Study in the Risk Game","Lana Bertoldo Rossato, Leonardo Boaventura Bombardelli, Anderson Rocha Tavares","Artificial Intelligence (cs.AI)","Creating and evaluating games manually is an arduous and laborious task. Procedural content generation can aid by creating game artifacts, but usually not an entire game. Evolutionary game design, which combines evolutionary algorithms with automated playtesting, has been used to create novel board games with simple equipment; however, the original approach does not include complex tabletop games with dice, cards, and maps. This work proposes an extension of the approach for tabletop games, evaluating the process by generating variants of Risk, a military strategy game where players must conquer map territories to win. We achieved this using a genetic algorithm to evolve the chosen parameters, as well as a rules-based agent to test the games and a variety of quality criteria to evaluate the new variations generated. Our results show the creation of new variations of the original game with smaller maps, resulting in shorter matches. Also, the variants produce more balanced matches, maintaining the usual drama. We also identified limitations in the process, where, in many cases, where the objective function was correctly pursued, but the generated games were nearly trivial. This work paves the way towards promising research regarding the use of evolutionary game design beyond classic board games.","Mon, 30 Oct 2023 20:53:26 UTC (1,016 KB)[v2] Thu, 1 Feb 2024 15:55:02 UTC (1,016 KB)"
"89","Herd: Using multiple, smaller LLMs to match the performances of proprietary, large LLMs via an intelligent composer","Surya Narayanan Hari, Matt Thomson","Artificial Intelligence (cs.AI)","Currently, over a thousand LLMs exist that are multi-purpose and are capable of performing real world tasks, including Q&A, text summarization, content generation, etc. However, accessibility, scale and reliability of free models prevents them from being widely deployed in everyday use cases. To address the first two issues of access and scale, organisations such as HuggingFace have created model repositories where users have uploaded model weights and quantized versions of models trained using different paradigms, as well as model cards describing their training process. While some models report performance on commonly used benchmarks, not all do, and interpreting the real world impact of trading off performance on a benchmark for model deployment cost, is unclear. Here, we show that a herd of open source models can match or exceed the performance of proprietary models via an intelligent router. We show that a Herd of open source models is able to match the accuracy of ChatGPT, despite being composed of models that are effectively 2.5x smaller. We show that in cases where GPT is not able to answer the query, Herd is able to identify a model that can, at least 40% of the time.","Mon, 30 Oct 2023 18:11:02 UTC (10,063 KB)"
"90","Novel Developments on the OpenIPMC Project","Luigi Calligaris, Carlos R. Dell'Aquila, Antono Vitor Grossi Bassi, André Cascadan, Luis E. Ardila-Perez, Marvin Fuchs, Alp Akpinar, Andrew Peck, Daniel Gastler, Giacomo Fedi","Instrumentation and Detectors (physics.ins-det)","We present the recent developments in the context of the OpenIPMC project, which proposes a free and open-source Intelligent Platform Management Controller (IPMC) software and an associated controller mezzanine card for use in ATCA electronic boards. We discuss our experience in the operation of OpenIPMC on prototype boards designed for the upgrades of particle physics experiments at CERN and we show the addition of new features and support for new protocols in the firmware of the controller mezzanine card.","Mon, 30 Oct 2023 17:05:40 UTC (2,718 KB)[v2] Fri, 12 Jan 2024 20:29:37 UTC (3,700 KB)"
"91","Edge AI-Based Vein Detector for Efficient Venipuncture in the Antecubital Fossa","Edwin Salcedo, Patricia Peñaloza","Image and Video Processing (eess.IV)","Assessing the condition and visibility of veins is a crucial step before obtaining intravenous access in the antecubital fossa, which is a common procedure to draw blood or administer intravenous therapies (IV therapies). Even though medical practitioners are highly skilled at intravenous cannulation, they usually struggle to perform the procedure in patients with low visible veins due to fluid retention, age, overweight, dark skin tone, or diabetes. Recently, several investigations proposed combining Near Infrared (NIR) imaging and deep learning (DL) techniques for forearm vein segmentation. Although they have demonstrated compelling results, their use has been rather limited owing to the portability and precision requirements to perform venipuncture. In this paper, we aim to contribute to bridging this gap using three strategies. First, we introduce a new NIR-based forearm vein segmentation dataset of 2,016 labelled images collected from 1,008 subjects with low visible veins. Second, we propose a modified U-Net architecture that locates veins specifically in the antecubital fossa region of the examined patient. Finally, a compressed version of the proposed architecture was deployed inside a bespoke, portable vein finder device after testing four common embedded microcomputers and four common quantization modalities. Experimental results showed that the model compressed with Dynamic Range Quantization and deployed on a Raspberry Pi 4B card produced the best execution time and precision balance, with 5.14 FPS and 0.957 of latency and Intersection over Union (IoU), respectively. These results show promising performance inside a resource-restricted low-cost device.","Fri, 27 Oct 2023 16:19:26 UTC (5,152 KB)"
"92","All-rounder: A flexible DNN accelerator with diverse data format support","Seock-Hwan Noh, Seungpyo Lee, Banseok Shin, Sehun Park, Yongjoo Jang, Jaeha Kung","Hardware Architecture (cs.AR)","Recognizing the explosive increase in the use of DNN-based applications, several industrial companies developed a custom ASIC (e.g., Google TPU, IBM RaPiD, Intel NNP-I/NNP-T) and constructed a hyperscale cloud infrastructure with it. The ASIC performs operations of the inference or training process of DNN models which are requested by users. Since the DNN models have different data formats and types of operations, the ASIC needs to support diverse data formats and generality for the operations. However, the conventional ASICs do not fulfill these requirements. To overcome the limitations of it, we propose a flexible DNN accelerator called All-rounder. The accelerator is designed with an area-efficient multiplier supporting multiple precisions of integer and floating point datatypes. In addition, it constitutes a flexibly fusible and fissionable MAC array to support various types of DNN operations efficiently. We implemented the register transfer level (RTL) design using Verilog and synthesized it in 28nm CMOS technology. To examine practical effectiveness of our proposed designs, we designed two multiply units and three state-of-the-art DNN accelerators. We compare our multiplier with the multiply units and perform architectural evaluation on performance and energy efficiency with eight real-world DNN models. Furthermore, we compare benefits of the All-rounder accelerator to a high-end GPU card, i.e., NVIDIA GeForce RTX30390. The proposed All-rounder accelerator universally has speedup and high energy efficiency in various DNN benchmarks than the baselines.","Wed, 25 Oct 2023 16:45:02 UTC (10,485 KB)"
"93","Is a humorous robot more trustworthy?","Barbara Sienkiewicz, Bipin Indurkhya","Human-Computer Interaction (cs.HC)","As more and more social robots are being used for collaborative activities with humans, it is crucial to investigate mechanisms to facilitate trust in the human-robot interaction. One such mechanism is humour: it has been shown to increase creativity and productivity in human-human interaction, which has an indirect influence on trust. In this study, we investigate if humour can increase trust in human-robot interaction. We conducted a between-subjects experiment with 40 participants to see if the participants are more likely to accept the robot's suggestion in the Three-card Monte game, as a trust check task. Though we were unable to find a significant effect of humour, we discuss the effect of possible confounding variables, and also report some interesting qualitative observations from our study: for instance, the participants interacted effectively with the robot as a team member, regardless of the humour or no-humour condition.","Tue, 24 Oct 2023 14:22:09 UTC (1,456 KB)"
"94","Mixing Time of the Overlapping Cycles Shuffle","Olena Blumberg, Ben Morris, Hans Oberschelp","Probability (math.PR)","In each step of the overlapping cycles shuffle on $n$ cards, a fair coin is flipped which determines whether the $m$th card or the $n$th card is moved to the top of the deck. Angel, Peres, and Wilson showed the following interesting fact: If $m = \lfloor \alpha n \rfloor$ where $\alpha$ is rational, then the relaxation time of a single card in the overlapping cycles shuffle is $\theta(n^2)$. However if $\alpha$ is the golden ratio, then the relaxation time of a single card is $\theta(n^\frac{3}{2})$. We show that the mixing time of the entire deck under the overlapping cycles shuffle matches these bounds up to a factor of $\log(n)^3$. That is, the mixing time of the entire deck is $O(n^2 \log(n)^3)$ if $\alpha$ is rational and $O(n^\frac{3}{2} \log(n)^3)$ if $\alpha$ is the golden ratio.","Tue, 24 Oct 2023 01:18:04 UTC (562 KB)[v2] Wed, 1 Nov 2023 04:25:15 UTC (562 KB)[v3] Sun, 12 Nov 2023 22:21:02 UTC (562 KB)"
"95","My Lockdown Escape: Sparking Self-Empathy in the Context of the Covid-19 Pandemic","Andrea Tocchetti, Silvia Maria Talenti, Marco Brambilla","Human-Computer Interaction (cs.HC)","During the Covid-19 pandemic, research communities focused on collecting and understanding people's behaviours and feelings to study and tackle the pandemic indirect effects. Despite its consequences are slowly starting to fade away, such an interest is still alive. In this article, we propose a hybrid, gamified, story-driven data collection approach to spark self-empathy, hence resurfacing people's past feelings. The game is designed to include a physical board, decks of cards, and a digital application. As the player plays through the game, they customize and escape from their lockdown room by completing statements and answering a series of questions that define their story. The decoration of the lockdown room and the storytelling-driven approach are targeted at sparking people's emotions and self-empathy towards their past selves. Ultimately, the proposed approach was proven effective in sparking and collecting feelings, while a few improvements are still necessary.","Mon, 23 Oct 2023 14:33:17 UTC (1,056 KB)"
"96","Take the aTrain. Introducing an Interface for the Accessible Transcription of Interviews","Armin Haberl, Jürgen Fleiß, Dominik Kowald, Stefan Thalmann","Sound (cs.SD)","aTrain is an open-source and offline tool for transcribing audio data in multiple languages with CPU and NVIDIA GPU support. It is specifically designed for researchers using qualitative data generated from various forms of speech interactions with research participants. aTrain requires no programming skills, runs on most computers, does not require an internet connection, and was verified not to upload data to any server. aTrain combines OpenAI's Whisper model with speaker recognition to provide output that integrates with the popular qualitative data analysis software tools MAXQDA and ATLAS.ti. It has an easy-to-use graphical interface and is provided as a Windows-App through the Microsoft Store allowing for simple installation by researchers. The source code is freely available on GitHub. Having developed aTrain with a focus on speed on local computers, we show that the transcription time on current mobile CPUs is around 2 to 3 times the duration of the audio file using the highest-accuracy transcription models. If an entry-level graphics card is available, the transcription speed increases to 20% of the audio duration.","Wed, 18 Oct 2023 13:45:47 UTC (464 KB)"
"97","FuseSR: Super Resolution for Real-time Rendering through Efficient Multi-resolution Fusion","Zhihua Zhong, Jingsen Zhu, Yuxin Dai, Chuankun Zheng, Yuchi Huo, Guanlin Chen, Hujun Bao, Rui Wang","Graphics (cs.GR)","The workload of real-time rendering is steeply increasing as the demand for high resolution, high refresh rates, and high realism rises, overwhelming most graphics cards. To mitigate this problem, one of the most popular solutions is to render images at a low resolution to reduce rendering overhead, and then manage to accurately upsample the low-resolution rendered image to the target resolution, a.k.a. super-resolution techniques. Most existing methods focus on exploiting information from low-resolution inputs, such as historical frames. The absence of high frequency details in those LR inputs makes them hard to recover fine details in their high-resolution predictions. In this paper, we propose an efficient and effective super-resolution method that predicts high-quality upsampled reconstructions utilizing low-cost high-resolution auxiliary G-Buffers as additional input. With LR images and HR G-buffers as input, the network requires to align and fuse features at multi resolution levels. We introduce an efficient and effective H-Net architecture to solve this problem and significantly reduce rendering overhead without noticeable quality deterioration. Experiments show that our method is able to produce temporally consistent reconstructions in $4 \times 4$ and even challenging $8 \times 8$ upsampling cases at 4K resolution with real-time performance, with substantially improved quality and significant performance boost compared to existing works.","Sun, 15 Oct 2023 04:01:05 UTC (29,576 KB)"
"98","Maximum Number of Quads","Nikhil Byrapuram, Hwiseo (Irene)Choi, Adam Ge, Selena Ge, Tanya Khovanova, Sylvia Zia Lee, Evin Liang, Rajarshi Mandal, Aika Oki, Daniel Wu, Michael Yang","Combinatorics (math.CO)","We study the maximum number of quads among $\ell$ cards from an EvenQuads deck of size $2^n$. This corresponds to enumerating quadruples of integers in the range $[0,\ell-1]$ such that their bitwise XOR is zero. In this paper, we conjecture a formula that calculates the maximum number of quads among $\ell$ cards.","Sun, 15 Oct 2023 01:13:03 UTC (11 KB)"
"99","STORM: Efficient Stochastic Transformer based World Models for Reinforcement Learning","Weipu Zhang, Gang Wang, Jian Sun, Yetian Yuan, Gao Huang","Machine Learning (cs.LG)","Recently, model-based reinforcement learning algorithms have demonstrated remarkable efficacy in visual input environments. These approaches begin by constructing a parameterized simulation world model of the real environment through self-supervised learning. By leveraging the imagination of the world model, the agent's policy is enhanced without the constraints of sampling from the real environment. The performance of these algorithms heavily relies on the sequence modeling and generation capabilities of the world model. However, constructing a perfectly accurate model of a complex unknown environment is nearly impossible. Discrepancies between the model and reality may cause the agent to pursue virtual goals, resulting in subpar performance in the real environment. Introducing random noise into model-based reinforcement learning has been proven beneficial. In this work, we introduce Stochastic Transformer-based wORld Model (STORM), an efficient world model architecture that combines the strong sequence modeling and generation capabilities of Transformers with the stochastic nature of variational autoencoders. STORM achieves a mean human performance of $126.7\%$ on the Atari $100$k benchmark, setting a new record among state-of-the-art methods that do not employ lookahead search techniques. Moreover, training an agent with $1.85$ hours of real-time interaction experience on a single NVIDIA GeForce RTX 3090 graphics card requires only $4.3$ hours, showcasing improved efficiency compared to previous methodologies.","Sat, 14 Oct 2023 16:42:02 UTC (1,328 KB)"
"100","SAI: Solving AI Tasks with Systematic Artificial Intelligence in Communication Network","Lei Yao, Yong Zhang, Zilong Yan, Jialu Tian","Artificial Intelligence (cs.AI)","In the rapid development of artificial intelligence, solving complex AI tasks is a crucial technology in intelligent mobile networks. Despite the good performance of specialized AI models in intelligent mobile networks, they are unable to handle complicated AI tasks. To address this challenge, we propose Systematic Artificial Intelligence (SAI), which is a framework designed to solve AI tasks by leveraging Large Language Models (LLMs) and JSON-format intent-based input to connect self-designed model library and database. Specifically, we first design a multi-input component, which simultaneously integrates Large Language Models (LLMs) and JSON-format intent-based inputs to fulfill the diverse intent requirements of different users. In addition, we introduce a model library module based on model cards which employ model cards to pairwise match between different modules for model composition. Model cards contain the corresponding model's name and the required performance metrics. Then when receiving user network requirements, we execute each subtask for multiple selected model combinations and provide output based on the execution results and LLM feedback. By leveraging the language capabilities of LLMs and the abundant AI models in the model library, SAI can complete numerous complex AI tasks in the communication network, achieving impressive results in network optimization, resource allocation, and other challenging tasks.","Fri, 13 Oct 2023 12:14:58 UTC (154 KB)"
"101","Recurrent networks recognize patterns with low-dimensional oscillations","Keith T. Murray","Neurons and Cognition (q-bio.NC)","This study proposes a novel dynamical mechanism for pattern recognition discovered by interpreting a recurrent neural network (RNN) trained on a simple task inspired by the SET card game. We interpreted the trained RNN as recognizing patterns via phase shifts in a low-dimensional limit cycle in a manner analogous to transitions in a finite state automaton (FSA). We further validated this interpretation by handcrafting a simple oscillatory model that reproduces the dynamics of the trained RNN. Our findings not only suggest of a potential dynamical mechanism capable of pattern recognition, but also suggest of a potential neural implementation of FSA. Above all, this work contributes to the growing discourse on deep learning model interpretability.","Wed, 11 Oct 2023 21:25:12 UTC (1,859 KB)"
"102","Causal inference for disruption management in urban metro networks","Nan Zhang, Daniel Horcher, Prateek Bansal, Daniel J. Graham","Applications (stat.AP)","Urban metro systems can provide highly efficient and effective movements of vast passenger volumes in cities, but they are often affected by disruptions, causing delays, crowding, and ultimately a decline in passenger satisfaction and patronage. To manage and mitigate such adverse consequences, metro operators could benefit greatly from a quantitative understanding of the causal impact of disruptions. Such information would allow them to predict future delays, prepare effective recovery plans, and develop real-time information systems for passengers on trip re-routing options. In this paper, we develop a performance evaluation tool for metro operators that can quantify the causal effects of service disruptions on passenger flows, journey times, travel speeds and crowding densities. Our modelling framework is simple to implement, robust to statistical sources of bias, and can be used with high-frequency large-scale smart card data (over 4.85 million daily trips in our case) and train movement data. We recover disruption effects at the points of disruption (e.g. at disrupted stations) as well as spillover effects that propagate throughout the metro network. This allows us to deliver novel insights on the spatio-temporal propagation of delays in densely used urban public transport networks. We find robust empirical evidence that the causal impacts of disruptions adversely affect service quality throughout the network, in ways that would be hard to predict absent a causal model.","Wed, 11 Oct 2023 14:11:42 UTC (837 KB)"
"103","The Control System of the Elliptical Cavity and Cryomodule Test Stand Demonstrator for ESS","Alexis Gaget (IRFU), Tom Joannem (IRFU), Adelino Gomes (IRFU), Yves Lussignol (IRFU), Jean-Francois Lecointe (IRFU), Quentin Bertrand (IRFU)","Accelerator Physics (physics.acc-ph)","CEA IRFU Saclay is taking part of ESS (European Spallation Source) construction through several packages and, especially in the last three years on the Elliptical Cavity and Cryomodule Test stand Demonstrator (ECCTD). The project consists of RF test, conditioning, cryogenic cool-down and regulations of eight cryomodules with theirs four cavities each. For now, two medium beta cavities cryomodules have been successfully tested. This paper describes the context and the realization of the control system for cryogenic and RF processes, added to cavities tuning motorization relying on COTS solutions: Siemens PLC, EtherCAT Beckhoff modules, IOxOS fast acquisition cards and MRF timing cards.","Wed, 11 Oct 2023 07:55:45 UTC (863 KB)"
"104","CarDS-Plus ECG Platform: Development and Feasibility Evaluation of a Multiplatform Artificial Intelligence Toolkit for Portable and Wearable Device Electrocardiograms","Sumukh Vasisht Shankar, Evangelos K Oikonomou, Rohan Khera","Machine Learning (cs.LG)","In the rapidly evolving landscape of modern healthcare, the integration of wearable & portable technology provides a unique opportunity for personalized health monitoring in the community. Devices like the Apple Watch, FitBit, and AliveCor KardiaMobile have revolutionized the acquisition and processing of intricate health data streams. Amidst the variety of data collected by these gadgets, single-lead electrocardiogram (ECG) recordings have emerged as a crucial source of information for monitoring cardiovascular health. There has been significant advances in artificial intelligence capable of interpreting these 1-lead ECGs, facilitating clinical diagnosis as well as the detection of rare cardiac disorders. This design study describes the development of an innovative multiplatform system aimed at the rapid deployment of AI-based ECG solutions for clinical investigation & care delivery. The study examines design considerations, aligning them with specific applications, develops data flows to maximize efficiency for research & clinical use. This process encompasses the reception of single-lead ECGs from diverse wearable devices, channeling this data into a centralized data lake & facilitating real-time inference through AI models for ECG interpretation. An evaluation of the platform demonstrates a mean duration from acquisition to reporting of results of 33.0 to 35.7 seconds, after a standard 30 second acquisition. There were no substantial differences in acquisition to reporting across two commercially available devices (Apple Watch and KardiaMobile). These results demonstrate the succcessful translation of design principles into a fully integrated & efficient strategy for leveraging 1-lead ECGs across platforms & interpretation by AI-ECG algorithms. Such a platform is critical to translating AI discoveries for wearable and portable ECG devices to clinical impact through rapid deployment.","Tue, 10 Oct 2023 20:33:48 UTC (2,076 KB)"
"105","BridgeHand2Vec Bridge Hand Representation","Anna Sztyber-Betley, Filip Kołodziej, Jan Betley, Piotr Duszak","Artificial Intelligence (cs.AI)","Contract bridge is a game characterized by incomplete information, posing an exciting challenge for artificial intelligence methods. This paper proposes the BridgeHand2Vec approach, which leverages a neural network to embed a bridge player's hand (consisting of 13 cards) into a vector space. The resulting representation reflects the strength of the hand in the game and enables interpretable distances to be determined between different hands. This representation is derived by training a neural network to estimate the number of tricks that a pair of players can take. In the remainder of this paper, we analyze the properties of the resulting vector space and provide examples of its application in reinforcement learning, and opening bid classification. Although this was not our main goal, the neural network used for the vectorization achieves SOTA results on the DDBP2 problem (estimating the number of tricks for two given hands).","Tue, 10 Oct 2023 13:41:41 UTC (1,404 KB)"
"106","Control in EPICS for Conditioning Test Stands for ESS","Alexis Gaget (IRFU), Adelino Gomes (IRFU), Yves Lussignol (IRFU)","Accelerator Physics (physics.acc-ph)","CEA Irfu Saclay is involved as partner in the ESS accelerator construction through different work-packages: controls for several RF test stands, for cryomodule demonstrators, for the RFQ coupler test and for the conditioning around 120 couplers and the tests of 8 cryomodules. Due to the high number of components it is really crucial to automatize the conditioning. This paper describes how the control of these test stands was done using the ESS EPICS Environment and homemade EPICS modules. These custom modules were designed to be as generic as possible for reuse in future similar platforms and developments. They rely on the IOxOS FMC ADC3111 acquisition card, Beckhoff EtherCAT modules and the MRF timing system.","Tue, 10 Oct 2023 12:38:05 UTC (944 KB)"
"107","Emergency Financing Tokens","Geoffrey Goodell","Computers and Society (cs.CY)","We propose a novel payment mechanism for use by victims of large-scale conflict or natural disasters to conduct critical economic transactions and rebuild damaged infrastructure in the absence of both cash and traditional electronic payment mechanisms linked to bank accounts, such as debit cards or wire transfers. Claimants shall receive electronic tokens that can be used to pay registered businesses, such as purveyors of food and other basic goods, providers of essential services, and contractors to carry out construction tasks. The system shall be based upon the scalable architecture for retail payments described in our earlier work, which provides both strong privacy for consumers and strong compliance enforcement for recipients of funds. The system shall be designed to achieve three main objectives. First, tokens issued to claimants would be held directly by the claimants themselves, not via intermediaries, to avoid the risk of failure or subversion of asset custodians. Second, transactions shall not be traceable to the identity of the claimants, thus mitigating the risk that claimants can be pressured by service providers or other parties to reveal information that can be used to exploit them. Third, businesses and service providers that receive tokens shall be subject to rigorous compliance procedures upon redemption for cash or bank deposits, thus ensuring that only legitimate businesses or service providers can receive value from tokens, that token transfers will embed the identities of any recipients beyond the initial claimant, and that tax obligations shall be met at the time of redemption.","Mon, 9 Oct 2023 06:12:21 UTC (153 KB)"
"108","Credit card score prediction using machine learning models: A new dataset","Anas Arram, Masri Ayob, Musatafa Abbas Abbood Albadr, Alaa Sulaiman, Dheeb Albashish","Machine Learning (cs.LG)","The use of credit cards has recently increased, creating an essential need for credit card assessment methods to minimize potential risks. This study investigates the utilization of machine learning (ML) models for credit card default prediction system. The main goal here is to investigate the best-performing ML model for new proposed credit card scoring dataset. This new dataset includes credit card transaction histories and customer profiles, is proposed and tested using a variety of machine learning algorithms, including logistic regression, decision trees, random forests, multi-layer perceptron (MLP) neural network, XGBoost, and LightGBM. To prepare the data for machine learning models, we perform data pre-processing, feature extraction, feature selection, and data balancing techniques. Experimental results demonstrate that MLP outperforms logistic regression, decision trees, random forests, LightGBM, and XGBoost in terms of predictive performance in true positive rate, achieving an impressive area under the curve (AUC) of 86.7% and an accuracy rate of 91.6%, with a recall rate exceeding 80%. These results indicate the superiority of MLP in predicting the default customers and assessing the potential risks. Furthermore, they help banks and other financial institutions in predicting loan defaults at an earlier stage.","Wed, 4 Oct 2023 16:46:26 UTC (211 KB)[v2] Sun, 15 Oct 2023 06:27:58 UTC (211 KB)"
"109","Quantum Algorithm Cards: Streamlining the development of hybrid classical-quantum applications","Vlad Stirbu, Majid Haghparast","Software Engineering (cs.SE)","The emergence of quantum computing proposes a revolutionary paradigm that can radically transform numerous scientific and industrial application domains. The ability of quantum computers to scale computations implies better performance and efficiency for certain algorithmic tasks than current computers provide. However, to gain benefit from such improvement, quantum computers must be integrated with existing software systems, a process that is not straightforward. In this paper, we investigate challenges that emerge when building larger hybrid classical-quantum computers and introduce the Quantum Algorithm Card (QAC) concept, an approach that could be employed to facilitate the decision making process around quantum technology.","Wed, 4 Oct 2023 06:02:59 UTC (66 KB)"
"110","The temporal concentration of travel demand in an urban transport network","Carmen Cabrera-Arnau, Liang Wei Ng, Howard Wong, Chen Zhong","Physics and Society (physics.soc-ph)","Suppose $A$ and $B$ are two stations within the mass rapid transit network of a city. Both stations see approximately the same average daily number of passengers entering and exiting their gates. However, passengers are evenly distributed at $A$, whereas activity is concentrated mainly during peak hours at $B$. Although the daily travel demand is the same for both stations, $B$ requires more resources since the number of vehicles, station dimensions and staffing level must be tailored to meet the demands of peak hours. This hypothetical scenario underscores the need to quantify the concentration of travel demand for optimising resource allocation and planning efficiency in an urban transport network. To this end, we introduce a novel metric for assessing the temporal concentration of travel demand at different locations in a generic transport network. Our approach is validated using granular data sourced from smart travel cards, encompassing 272 London Underground (LU) stations. Additionally, we present a methodological framework based on Random Forests to identify attributes of the locations of interest within the transport network that contribute to varying levels of temporal concentration of travel demand. Our case study unveils that LU stations located in areas characterised by low residential, retail, and employment density, predominantly situated in outer London, exhibit the most pronounced temporal concentration of travel demand. Conversely, within inner London, stations servicing high-density employment zones, especially around the City of London, experience a greater temporal concentration of travel demand compared to those catering to commercial and residential districts, typically situated in West London.","Tue, 3 Oct 2023 19:09:53 UTC (2,584 KB)"
"111","Transformers are efficient hierarchical chemical graph learners","Zihan Pengmei, Zimu Li, Chih-chan Tien, Risi Kondor, Aaron R. Dinner","Machine Learning (cs.LG)","Transformers, adapted from natural language processing, are emerging as a leading approach for graph representation learning. Contemporary graph transformers often treat nodes or edges as separate tokens. This approach leads to computational challenges for even moderately-sized graphs due to the quadratic scaling of self-attention complexity with token count. In this paper, we introduce SubFormer, a graph transformer that operates on subgraphs that aggregate information by a message-passing mechanism. This approach reduces the number of tokens and enhances learning long-range interactions. We demonstrate SubFormer on benchmarks for predicting molecular properties from chemical structures and show that it is competitive with state-of-the-art graph transformers at a fraction of the computational cost, with training times on the order of minutes on a consumer-grade graphics card. We interpret the attention weights in terms of chemical structures. We show that SubFormer exhibits limited over-smoothing and avoids over-squashing, which is prevalent in traditional graph neural networks.","Mon, 2 Oct 2023 23:57:04 UTC (3,333 KB)"
"112","EvenQuads Game and Error-Correcting Codes","Nikhil Byrapuram, Hwiseo (Irene)Choi, Adam Ge, Selena Ge, Tanya Khovanova, Sylvia Zia Lee, Evin Liang, Rajarshi Mandal, Aika Oki, Daniel Wu, Michael Yang","Combinatorics (math.CO)","EvenQuads is a new card game that is a generalization of the SET game, where each card is characterized by three attributes, each taking four possible values. Four cards form a quad when, for each attribute, the values are the same, all different, or half and half. Given $\ell$ cards from the deck of EvenQuads, we can build an error-correcting linear binary code of length $\ell$ and Hamming distance 4. The quads correspond to codewords of weight 4. Error-correcting codes help us calculate the possible number of quads when given up to 8 cards. We also estimate the number of cards that do not contain quads for decks of different sizes. In addition, we discuss properties of error-correcting codes built on semimagic, magic, and strongly magic quad squares.","Mon, 2 Oct 2023 14:50:05 UTC (17 KB)"
"113","All by Myself: Learning Individualized Competitive Behaviour with a Contrastive Reinforcement Learning optimization","Pablo Barros, Alessandra Sciutti","Artificial Intelligence (cs.AI)","In a competitive game scenario, a set of agents have to learn decisions that maximize their goals and minimize their adversaries' goals at the same time. Besides dealing with the increased dynamics of the scenarios due to the opponents' actions, they usually have to understand how to overcome the opponent's strategies. Most of the common solutions, usually based on continual learning or centralized multi-agent experiences, however, do not allow the development of personalized strategies to face individual opponents. In this paper, we propose a novel model composed of three neural layers that learn a representation of a competitive game, learn how to map the strategy of specific opponents, and how to disrupt them. The entire model is trained online, using a composed loss based on a contrastive optimization, to learn competitive and multiplayer games. We evaluate our model on a pokemon duel scenario and the four-player competitive Chef's Hat card game. Our experiments demonstrate that our model achieves better performance when playing against offline, online, and competitive-specific models, in particular when playing against the same opponent multiple times. We also present a discussion on the impact of our model, in particular on how well it deals with on specific strategy learning for each of the two scenarios.","Mon, 2 Oct 2023 08:11:07 UTC (5,728 KB)"
"114","Suspicion-Agent: Playing Imperfect Information Games with Theory of Mind Aware GPT-4","Jiaxian Guo, Bo Yang, Paul Yoo, Bill Yuchen Lin, Yusuke Iwasawa, Yutaka Matsuo","Artificial Intelligence (cs.AI)","Unlike perfect information games, where all elements are known to every player, imperfect information games emulate the real-world complexities of decision-making under uncertain or incomplete information. GPT-4, the recent breakthrough in large language models (LLMs) trained on massive passive data, is notable for its knowledge retrieval and reasoning abilities. This paper delves into the applicability of GPT-4's learned knowledge for imperfect information games. To achieve this, we introduce \textbf{Suspicion-Agent}, an innovative agent that leverages GPT-4's capabilities for performing in imperfect information games. With proper prompt engineering to achieve different functions, Suspicion-Agent based on GPT-4 demonstrates remarkable adaptability across a range of imperfect information card games. Importantly, GPT-4 displays a strong high-order theory of mind (ToM) capacity, meaning it can understand others and intentionally impact others' behavior. Leveraging this, we design a planning strategy that enables GPT-4 to competently play against different opponents, adapting its gameplay style as needed, while requiring only the game rules and descriptions of observations as input. In the experiments, we qualitatively showcase the capabilities of Suspicion-Agent across three different imperfect information games and then quantitatively evaluate it in Leduc Hold'em. The results show that Suspicion-Agent can potentially outperform traditional algorithms designed for imperfect information games, without any specialized training or examples. In order to encourage and foster deeper insights within the community, we make our game-related data publicly available.","Fri, 29 Sep 2023 14:30:03 UTC (5,480 KB)[v2] Fri, 6 Oct 2023 04:03:55 UTC (5,480 KB)"
"115","A Tale of Two Cultures: Comparing Interpersonal Information Disclosure Norms on Twitter","Mainack Mondal, Anju Punuru, Tyng-Wen Scott Cheng, Kenneth Vargas, Chaz Gundry, Nathan S Driggs, Noah Schill, Nathaniel Carlson, Josh Bedwell, Jaden Q Lorenc, Isha Ghosh, Yao Li, Nancy Fulda, Xinru Page","Human-Computer Interaction (cs.HC)","We present an exploration of cultural norms surrounding online disclosure of information about one's interpersonal relationships (such as information about family members, colleagues, friends, or lovers) on Twitter. The literature identifies the cultural dimension of individualism versus collectivism as being a major determinant of offline communication differences in terms of emotion, topic, and content disclosed. We decided to study whether such differences also occur online in context of Twitter when comparing tweets posted in an individualistic (U.S.) versus a collectivist (India) society. We collected more than 2 million tweets posted in the U.S. and India over a 3 month period which contain interpersonal relationship keywords. A card-sort study was used to develop this culturally-sensitive saturated taxonomy of keywords that represent interpersonal relationships (e.g., ma, mom, mother). Then we developed a high-accuracy interpersonal disclosure detector based on dependency-parsing (F1-score: 86%) to identify when the words refer to a personal relationship of the poster (e.g., ""my mom"" as opposed to ""a mom""). This allowed us to identify the 400K+ tweets in our data set which actually disclose information about the poster's interpersonal relationships. We used a mixed methods approach to analyze these tweets (e.g., comparing the amount of joy expressed about one's family) and found differences in emotion, topic, and content disclosed between tweets from the U.S. versus India. Our analysis also reveals how a combination of qualitative and quantitative methods are needed to uncover these differences; Using just one or the other can be misleading. This study extends the prior literature on Multi-Party Privacy and provides guidance for researchers and designers of culturally-sensitive systems.","Tue, 26 Sep 2023 18:55:48 UTC (21,907 KB)"
"116","Credit Card Fraud Detection with Subspace Learning-based One-Class Classification","Zaffar Zaffar, Fahad Sohrab, Juho Kanniainen, Moncef Gabbouj","Machine Learning (cs.LG)","In an increasingly digitalized commerce landscape, the proliferation of credit card fraud and the evolution of sophisticated fraudulent techniques have led to substantial financial losses. Automating credit card fraud detection is a viable way to accelerate detection, reducing response times and minimizing potential financial losses. However, addressing this challenge is complicated by the highly imbalanced nature of the datasets, where genuine transactions vastly outnumber fraudulent ones. Furthermore, the high number of dimensions within the feature set gives rise to the ``curse of dimensionality"". In this paper, we investigate subspace learning-based approaches centered on One-Class Classification (OCC) algorithms, which excel in handling imbalanced data distributions and possess the capability to anticipate and counter the transactions carried out by yet-to-be-invented fraud techniques. The study highlights the potential of subspace learning-based OCC algorithms by investigating the limitations of current fraud detection strategies and the specific challenges of credit card fraud detection. These algorithms integrate subspace learning into the data description; hence, the models transform the data into a lower-dimensional subspace optimized for OCC. Through rigorous experimentation and analysis, the study validated that the proposed approach helps tackle the curse of dimensionality and the imbalanced nature of credit card data for automatic fraud detection to mitigate financial losses caused by fraudulent activities.","Tue, 26 Sep 2023 12:26:28 UTC (214 KB)"
"117","State-Compute Replication: Parallelizing High-Speed Stateful Packet Processing","Qiongwen Xu, Sebastiano Miano, Xiangyu Gao, Tao Wang, Songyuan Zhang, Anirudh Sivaraman, Gianni Antichi, Srinivas Narayana","Networking and Internet Architecture (cs.NI)","With the slowdown of Moore's law, CPU-oriented packet processing in software will be significantly outpaced by emerging line speeds of network interface cards (NICs). Single-core packet-processing throughput has saturated. We consider the problem of high-speed packet processing with multiple CPU cores. The key challenge is state--memory that multiple packets must read and update. The prevailing method to scale throughput with multiple cores involves state sharding, processing all packets that update the same state, i.e., flow, at the same core. However, given the heavy-tailed nature of realistic flow size distributions, this method will be untenable in the near future, since total throughput is severely limited by single core performance. This paper introduces state-compute replication, a principle to scale the throughput of a single stateful flow across multiple cores using replication. Our design leverages a packet history sequencer running on a NIC or top-of-the-rack switch to enable multiple cores to update state without explicit synchronization. Our experiments with realistic data center and wide-area Internet traces shows that state-compute replication can scale total packet-processing throughput linearly with cores, deterministically and independent of flow size distributions, across a range of realistic packet-processing programs.","Tue, 26 Sep 2023 03:55:46 UTC (417 KB)"
"118","More than Model Documentation: Uncovering Teachers' Bespoke Information Needs for Informed Classroom Integration of ChatGPT","Mei Tan, Hariharan Subramonyam","Human-Computer Interaction (cs.HC)","ChatGPT has entered classrooms, but not via the typical route of other educational technology, which includes comprehensive training, documentation, and vetting. Consequently, teachers are urgently tasked to assess its capabilities to determine potential effects on student learning and instruct their use of ChatGPT. However, it is unclear what support teachers have and need and whether existing documentation, such as model cards, provides adequate direction for educators in this new paradigm. By interviewing 22 middle- and high-school teachers, we connect the discourse on AI transparency and documentation with educational technology integration, highlighting the critical information needs of teachers. Our findings reveal that teachers confront significant information gaps, lacking clarity on exploring ChatGPT's capabilities for bespoke learning tasks and ensuring its fit with the needs of diverse learners. As a solution, we propose a framework for interactive model documentation that empowers teachers to navigate the interplay between pedagogical and technical knowledge.","Mon, 25 Sep 2023 18:43:07 UTC (837 KB)"
"119","Robust Principal Component Analysis using Density Power Divergence","Subhrajyoty Roy, Ayanendranath Basu, Abhik Ghosh","Methodology (stat.ME)","Principal component analysis (PCA) is a widely employed statistical tool used primarily for dimensionality reduction. However, it is known to be adversely affected by the presence of outlying observations in the sample, which is quite common. Robust PCA methods using M-estimators have theoretical benefits, but their robustness drop substantially for high dimensional data. On the other end of the spectrum, robust PCA algorithms solving principal component pursuit or similar optimization problems have high breakdown, but lack theoretical richness and demand high computational power compared to the M-estimators. We introduce a novel robust PCA estimator based on the minimum density power divergence estimator. This combines the theoretical strength of the M-estimators and the minimum divergence estimators with a high breakdown guarantee regardless of data dimension. We present a computationally efficient algorithm for this estimate. Our theoretical findings are supported by extensive simulations and comparisons with existing robust PCA methods. We also showcase the proposed algorithm's applicability on two benchmark datasets and a credit card transactions dataset for fraud detection.","Sun, 24 Sep 2023 02:59:39 UTC (3,391 KB)"
"120","WikiMT++ Dataset Card","Monan Zhou, Shangda Wu, Yuan Wang, Wei Li","Information Retrieval (cs.IR)","WikiMT++ is an expanded and refined version of WikiMusicText (WikiMT), featuring 1010 curated lead sheets in ABC notation. To expand application scenarios of WikiMT, we add both objective (album, lyrics, video) and subjective emotion (12 emotion adjectives) and emo\_4q (Russell 4Q) attributes, enhancing its usability for music information retrieval, conditional music generation, automatic composition, and emotion classification, etc. Additionally, CLaMP is implemented to correct the attributes inherited from WikiMT to reduce errors introduced during original data collection and enhance the accuracy and completeness of our dataset.","Sat, 23 Sep 2023 04:46:28 UTC (121 KB)"
"121","AI Risk Profiles: A Standards Proposal for Pre-Deployment AI Risk Disclosures","Eli Sherman, Ian W. Eisenberg","Artificial Intelligence (cs.AI)","As AI systems' sophistication and proliferation have increased, awareness of the risks has grown proportionally (Sorkin et al. 2023). In response, calls have grown for stronger emphasis on disclosure and transparency in the AI industry (NTIA 2023; OpenAI 2023b), with proposals ranging from standardizing use of technical disclosures, like model cards (Mitchell et al. 2019), to yet-unspecified licensing regimes (Sindhu 2023). Since the AI value chain is complicated, with actors representing various expertise, perspectives, and values, it is crucial that consumers of a transparency disclosure be able to understand the risks of the AI system the disclosure concerns. In this paper we propose a risk profiling standard which can guide downstream decision-making, including triaging further risk assessment, informing procurement and deployment, and directing regulatory frameworks. The standard is built on our proposed taxonomy of AI risks, which reflects a high-level categorization of the wide variety of risks proposed in the literature. We outline the myriad data sources needed to construct informative Risk Profiles and propose a template-based methodology for collating risk information into a standard, yet flexible, structure. We apply this methodology to a number of prominent AI systems using publicly available information. To conclude, we discuss design decisions for the profiles and future work.","Fri, 22 Sep 2023 20:45:15 UTC (873 KB)"
"122","Efficient N:M Sparse DNN Training Using Algorithm, Architecture, and Dataflow Co-Design","Chao Fang, Wei Sun, Aojun Zhou, Zhongfeng Wang","Machine Learning (cs.LG)","Sparse training is one of the promising techniques to reduce the computational cost of DNNs while retaining high accuracy. In particular, N:M fine-grained structured sparsity, where only N out of consecutive M elements can be nonzero, has attracted attention due to its hardware-friendly pattern and capability of achieving a high sparse ratio. However, the potential to accelerate N:M sparse DNN training has not been fully exploited, and there is a lack of efficient hardware supporting N:M sparse training. To tackle these challenges, this paper presents a computation-efficient training scheme for N:M sparse DNNs using algorithm, architecture, and dataflow co-design. At the algorithm level, a bidirectional weight pruning method, dubbed BDWP, is proposed to leverage the N:M sparsity of weights during both forward and backward passes of DNN training, which can significantly reduce the computational cost while maintaining model accuracy. At the architecture level, a sparse accelerator for DNN training, namely SAT, is developed to neatly support both the regular dense operations and the computation-efficient N:M sparse operations. At the dataflow level, multiple optimization methods ranging from interleave mapping, pre-generation of N:M sparse weights, and offline scheduling, are proposed to boost the computational efficiency of SAT. Finally, the effectiveness of our training scheme is evaluated on a Xilinx VCU1525 FPGA card using various DNN models and datasets. Experimental results show the SAT accelerator with the BDWP sparse training method under 2:8 sparse ratio achieves an average speedup of 1.75x over that with the dense training, accompanied by a negligible accuracy loss of 0.56% on average. Furthermore, our proposed training scheme significantly improves the training throughput by 2.97~25.22x and the energy efficiency by 1.36~3.58x over prior FPGA-based accelerators.","Fri, 22 Sep 2023 17:26:19 UTC (813 KB)"
"123","Unlocking Model Insights: A Dataset for Automated Model Card Generation","Shruti Singh, Hitesh Lodwal, Husain Malwat, Rakesh Thakur, Mayank Singh","Computation and Language (cs.CL)","Language models (LMs) are no longer restricted to ML community, and instruction-tuned LMs have led to a rise in autonomous AI agents. As the accessibility of LMs grows, it is imperative that an understanding of their capabilities, intended usage, and development cycle also improves. Model cards are a popular practice for documenting detailed information about an ML model. To automate model card generation, we introduce a dataset of 500 question-answer pairs for 25 ML models that cover crucial aspects of the model, such as its training configurations, datasets, biases, architecture details, and training resources. We employ annotators to extract the answers from the original paper. Further, we explore the capabilities of LMs in generating model cards by answering questions. Our initial experiments with ChatGPT-3.5, LLaMa, and Galactica showcase a significant gap in the understanding of research papers by these aforementioned LMs as well as generating factual textual responses. We posit that our dataset can be used to train models to automate the generation of model cards from paper text and reduce human effort in the model card curation process. The complete dataset is available on this https URL","Fri, 22 Sep 2023 04:46:11 UTC (7,796 KB)"
"124","Study on the sensitivity of the Higgs boson couplings in photon-photon collision at CLIC and muon collider","S. Spor","High Energy Physics - Phenomenology (hep-ph)","In a model-independent way, we explore the potential of photon-induced interactions with the process $\gamma^* \gamma^* \rightarrow ZZ$ to investigate CP-conserving and CP-violating dimension-six operators of Higgs-gauge boson couplings using the Standard Model Effective Field Theory (SMEFT). The existence of anomalous $H\gamma\gamma$ and $HZZ$ couplings is discussed at 3 TeV Compact Linear Collider (CLIC) and 10 TeV Muon Collider (MuC) with an integrated luminosity of 5 and 10 ab$^{-1}$, respectively. All signal and relevant background events are generated in MadGraph and passed through PYTHIA for parton showering and hadronization. Detector effects are evaluated via CLIC and MuC detector cards tuned in Delphes. We report the 95% confidence level limits on the Wilson coefficients $\overline{c}_\gamma$, $\overline{c}_{HB}$, $\overline{c}_{HW}$, $\widetilde{c}_\gamma$, $\widetilde{c}_{HB}$, $\widetilde{c}_{HW}$ and compare them with experimental and phenomenological limits.","Thu, 21 Sep 2023 21:42:20 UTC (736 KB)"
"125","Optimizing Traversing and Retrieval Speed of Large Breached Databases","Mayank Gite","Databases (cs.DB)","Breached data refers to the unauthorized access, theft, or exposure of confidential or sensitive information. Breaches typically occur when malicious actors or unauthorized users breach secure systems or networks, resulting in compromised personally identifiable information (PII), protected or personal health information (PHI), payment card industry (PCI) information, or other sensitive data. Data breaches are often the result of malicious activities such as hacking, phishing, insider threats, malware, or physical theft. The misuse of breached data can lead to identity theft, fraud, spamming, or blackmailing. Organizations that experience data breaches may face legal and financial consequences, reputational damage, and harm to their customers or users. Breached records are commonly sold on the dark web or made available on various public forums. To counteract these malicious activities, it is possible to collect breached databases and mitigate potential harm. These databases can be quite large, reaching sizes of up to 150 GB or more. Typically, breached data is stored in the CSV (Comma Separated Value) format due to its simplicity and lightweight nature, which reduces storage requirements. Analyzing and traversing large breached databases necessitates substantial computational power. However, this research explores techniques to optimize database traversal speed without the need to rent expensive cloud machines or virtual private servers (VPS). This optimization will enable individual security researchers to analyze and process large databases on their personal computer systems while significantly reducing costs.","Wed, 6 Sep 2023 13:11:18 UTC (573 KB)"
"126","Stylish Risk-Limiting Audits in Practice","Amanda K. Glazer, Jacob V. Spertus, Philip B. Stark","Applications (stat.AP)","Risk-limiting audits (RLAs) can use information about which ballot cards contain which contests (card-style data, CSD) to ensure that each contest receives adequate scrutiny, without examining more cards than necessary. RLAs using CSD in this way can be substantially more efficient than RLAs that sample indiscriminately from all cast cards. We describe an open-source Python implementation of RLAs using CSD for the Hart InterCivic Verity voting system and the Dominion Democracy Suite(R) voting system. The software is demonstrated using all 181 contests in the 2020 general election and all 214 contests in the 2022 general election in Orange County, CA, USA, the fifth-largest election jurisdiction in the U.S., with over 1.8 million active voters. (Orange County uses the Hart Verity system.) To audit the 181 contests in 2020 to a risk limit of 5% without using CSD would have required a complete hand tally of all 3,094,308 cast ballot cards. With CSD, the estimated sample size is about 20,100 cards, 0.65% of the cards cast--including one tied contest that required a complete hand count. To audit the 214 contests in 2022 to a risk limit of 5% without using CSD would have required a complete hand tally of all 1,989,416 cast cards. With CSD, the estimated sample size is about 62,250 ballots, 3.1% of cards cast--including three contests with margins below 0.1% and 9 with margins below 0.5%.","Sat, 16 Sep 2023 19:21:17 UTC (445 KB)"
"127","An Unified Search and Recommendation Foundation Model for Cold-Start Scenario","Yuqi Gong, Xichen Ding, Yehui Su, Kaiming Shen, Zhongyi Liu, Guannan Zhang","Information Retrieval (cs.IR)","In modern commercial search engines and recommendation systems, data from multiple domains is available to jointly train the multi-domain model. Traditional methods train multi-domain models in the multi-task setting, with shared parameters to learn the similarity of multiple tasks, and task-specific parameters to learn the divergence of features, labels, and sample distributions of individual tasks. With the development of large language models, LLM can extract global domain-invariant text features that serve both search and recommendation tasks. We propose a novel framework called S\&R Multi-Domain Foundation, which uses LLM to extract domain invariant features, and Aspect Gating Fusion to merge the ID feature, domain invariant text features and task-specific heterogeneous sparse features to obtain the representations of query and item. Additionally, samples from multiple search and recommendation scenarios are trained jointly with Domain Adaptive Multi-Task module to obtain the multi-domain foundation model. We apply the S\&R Multi-Domain foundation model to cold start scenarios in the pretrain-finetune manner, which achieves better performance than other SOTA transfer learning methods. The S\&R Multi-Domain Foundation model has been successfully deployed in Alipay Mobile Application's online services, such as content query recommendation and service card recommendation, etc.","Sat, 16 Sep 2023 10:00:02 UTC (4,969 KB)"
"128","A central limit theorem for a card shuffling problem","Shane Chern, Lin Jiu, Italo Simonelli","Probability (math.PR)","Given a positive integer $n$, consider a random permutation $\tau$ of the set $\{1,2,\ldots, n\}$. In $\tau$, we look for sequences of consecutive integers that appear in adjacent positions: a maximal such a sequence is called a block. Each block in $\tau$ is merged, and after all the merges, the elements of this new set are relabeled from $1$ to the current number of elements. We continue to randomly permute and merge this new set until only one integer is left. In this paper, we investigate the asymptotic behavior of $X_n$, the number of permutations needed for this process to end. In particular, we find an explicit asymptotic expression for each of $\mathbf{E}[X_n]$ and $\mathbf{Var} [X_n]$ as well as for every higher central moment, and show that $X_n$ satisfies a central limit theorem.","Sat, 16 Sep 2023 02:36:20 UTC (21 KB)"
"129","Speeding up the GENGA N-body integrator on consumer-grade graphics cards","R. Brasser, S. L. Grimm, P. Hatalova, J. G. Stadel","Earth and Planetary Astrophysics (astro-ph.EP)","GPU computing is popular due to the calculation potential of a single card. The N-body integrator GENGA is built to for this, but it suffers a performance penalty on consumer-grade GPUs due to their truncated double precision (FP64) performance. We aim to speed up GENGA on consumer-grade cards by harvesting their high single-precision performance (FP32). We modified GENGA to be able to compute the long-distance forces between bodies in FP32 precision and tested this with 5 experiments. We ran simulations with similar initial conditions of 6600 planetesimals in both FP32 and FP64 precision. We also ran simulations that i) began with a mixture of planetesimals and planetary embryos, ii) planetesimal-driven giant planet migration, and iii) terrestrial planet formation with a gas disc. Second, we ran the same simulation beginning with 40 000 planetesimals using both FP32 and FP64 precision forces on a variety of consumer-grade and Tesla GPUs to measure the performance boost of FP32 computing. There are no statistical differences when running in FP32 or FP64 precision that can be attributed to the force prescription rather than stochastic effects. The uncertainties in energy are almost identical when using both precisions. However, the uncertainty in the angular momentum using FP32 rather than FP64 precision long-range forces is about two orders of magnitude greater, but still very low. Running the simulations in single precision on consumer-grade cards decreases running time by a factor of three and becomes within a factor of three of a Tesla A100 GPU. Additional tuning speeds up the simulation by a factor of two across all types of cards. The option to compute the long-range forces in single precision in GENGA when using consumer-grade GPUs dramatically improves performance at a little penalty to accuracy. There is an additional environmental benefit because it reduces energy usage.","Fri, 15 Sep 2023 07:33:34 UTC (5,971 KB)"
"130","Commutator nilpotency for somewhere-to-below shuffles","Darij Grinberg","Combinatorics (math.CO)","Given a positive integer $n$, we consider the group algebra of the symmetric group $S_{n}$. In this algebra, we define $n$ elements $t_{1},t_{2},\ldots,t_{n}$ by the formula \[ t_{\ell}:=\operatorname*{cyc}\nolimits_{\ell}+\operatorname*{cyc}\nolimits_{\ell,\ell+1}+\operatorname*{cyc}\nolimits_{\ell,\ell+1,\ell+2}+\cdots+\operatorname*{cyc}\nolimits_{\ell,\ell+1,\ldots,n}, \] where $\operatorname*{cyc}\nolimits_{\ell,\ell+1,\ldots,k}$ denotes the cycle that sends $\ell\mapsto\ell+1\mapsto\ell+2\mapsto\cdots\mapsto k\mapsto\ell$. These $n$ elements are called the *somewhere-to-below shuffles* due to an interpretation as card-shuffling operators. In this paper, we show that their commutators $\left[ t_{i},t_{j}\right] =t_{i}t_{j}-t_{j}t_{i}$ are nilpotent, and specifically that \[ \left[ t_{i},t_{j}\right] ^{\left\lceil \left( n-j\right) /2\right\rceil +1}=0\ \ \ \ \ \ \ \ \ \ \text{for any }i,j\in\left\{ 1,2,\ldots,n\right\} \] and \[ \left[ t_{i},t_{j}\right] ^{j-i+1}=0\ \ \ \ \ \ \ \ \ \ \text{for any }1\leq i\leq j\leq n. \] We discuss some further identities and open questions.","Mon, 11 Sep 2023 09:37:33 UTC (37 KB)[v2] Wed, 20 Sep 2023 13:09:51 UTC (35 KB)"
"131","Provably Unlinkable Smart Card-based Payments","Sergiu Bursuc, Ross Horne, Sjouke Mauw, Semen Yurkov","Cryptography and Security (cs.CR)","The most prevalent smart card-based payment method, EMV, currently offers no privacy to its users. Transaction details and the card number are sent in cleartext, enabling the profiling and tracking of cardholders. Since public awareness of privacy issues is growing and legislation, such as GDPR, is emerging, we believe it is necessary to investigate the possibility of making payments anonymous and unlinkable without compromising essential security guarantees and functional properties of EMV. This paper draws attention to trade-offs between functional and privacy requirements in the design of such a protocol. We present the UTX protocol - an enhanced payment protocol satisfying such requirements, and we formally certify key security and privacy properties using techniques based on the applied pi-calculus.","Wed, 6 Sep 2023 16:06:40 UTC (1,122 KB)"
"132","Big Two and n-card poker probabilities","Brian Wu, Chai Wah Wu","History and Overview (math.HO)","Between the poker hands of straight, flush, and full house, which hand is more common? In standard 5-card poker, the order from most common to least common is straight, flush, full house. The same order is true for 7-card poker such as Texas hold'em. However, is the same true for n-card poker for larger n? We study the probability of obtaining these various hands for n-card poker for various values of $n\geq 5$. In particular, we derive equations for the probability of flush, straight and full house and show that the probability of flush is less than a straight when $n\leq 11$, and is more than a straight when n>11. Similarly, we show that the probability of full house is less than a straight when $n\leq 19$, and is more than a straight when n>19. This means that for games such as Big Two where the ordering of 13-card hands depends on the ordering in 5-card poker, the ranking ordering does not follow the occurrence probability ordering, contrary to what intuition suggests.","Wed, 16 Aug 2023 01:19:40 UTC (19 KB)"
"133","Study of Zero-Knowledge protocols and Elliptic Curve Cryptography and their implementation in Smart Card environments using Java Card","Carlos Andres Agudelo Serna","Cryptography and Security (cs.CR)","This paper studies the problem of Zero-Knowledge Protocol (ZKP) and elliptic curve cryptographic implementation in a computationally limited environment, such as, the smart cards, using Java Card. Besides that, it is explained how the zero-knowledge protocol was selected to implement it on a smart card and how the benchmarking was conducted to select this protocol. The paper also shows a theoretical development to implement the ZKP protocol using elliptic curve cryptography. Keywords: Authentication; Zero-knowledge; Cryptography; Elliptic Curve; Java card; Smart cards","Thu, 31 Aug 2023 12:15:03 UTC (513 KB)"
"134","On Card guessing games: limit law for no feedback one-time riffle shuffle","Markus Kuba, Alois Panholzer","Combinatorics (math.CO)","We consider the following card guessing game with no feedback. An ordered deck of n cards labeled 1 up to n is riffle-shuffled exactly one time. Then, the goal of the game is to maximize the number of correct guesses of the cards. One after another a single card is drawn from the top, the guesser makes a guess without seeing the card and gets no response if the guess was correct or not. Building upon and improving earlier results, we provide a limit law for the number of correct guesses and also show convergence of the integer moments.","Wed, 30 Aug 2023 06:28:01 UTC (69 KB)"
"135","Online Poker and Rummy -- Games of Skill or Chance?","Taranjit Kaur, Manas Pati Tripathi, Ashirbad Samantaray, Tapan K. Gandhi","Human-Computer Interaction (cs.HC)","The paper aims to investigate the degree of cognitive skills required for success in online versions of the popular card game rummy and poker. The study focuses on analyzing the impact of experience and learnable skills on success in the online card game. We also propose a framework to analyze online games to conclude on whether they are games of learnable skill or are they games of chance. The hypotheses proposed aim to test whether online and offline card games are comparable in terms of cognitive engagement and skill requirements. To assess these hypotheses, key elements of gameplay such as shuffling of cards, card deck randomness, and seating of players are analyzed. We also adopted statistical approaches to understand the characteristics of card games in terms of random chance or skill. From the analysis, we could see that the normality of the derived variables deviates significantly from the normal distribution showing a non-linear trend. It signifies that the mean of the involved skill variables is not zero as the user plays a greater number of games, thereby strengthening the assumption that the long-term success in online card games is attributed to skill and not chance. There is no difference in online and offline versions of card games (rummy and poker) from the perspective of requirement of skills. Moreover, our finding suggests that there is a preponderance of skills to succeed in online card gaming. Overall, the findings of this research contribute to a better understanding of cognitive skills in online gaming environments.","Mon, 28 Aug 2023 11:10:41 UTC (1,384 KB)"
"136","Probing the electromagnetic properties of the neutrinos at future lepton colliders","H. Denizli, A. Senol, M. Köksal","High Energy Physics - Phenomenology (hep-ph)","In this study, we explore the non-standard $\nu\bar{\nu}\gamma \gamma$ couplings parametrized by dimension-seven operators via $e^{+}e^{-} \to \nu\bar{\nu}\gamma$ process at the FCC-ee/CEPC and $\mu^{+}\mu^{-}\to\nu\bar{\nu}\gamma$ process at the Muon Colliders. For the detailed Monte Carlo simulation, all signal and relevant background events are produced within the framework of Madgraph where non-standard $\nu\bar{\nu}\gamma \gamma$ couplings are implemented. After passing through Pythia for parton showering and hadronization, detector effects are included via tuned corresponding detector cards for each collider in Delphes. Projected sensitivities on $\nu\bar{\nu}\gamma \gamma$ couplings are obtained at a 5$\sigma$ confidence level without and with $5\%$ systematic uncertainties for the FCC-ee/CEPC and the Muon Colliders, showcasing the complementarity between lepton colliders. Our best limit on the anomalous $\nu\bar{\nu}\gamma \gamma$ couplings even with 5\% systematic uncertainties for muon collider with $\sqrt{s}=10$ TeV and $L_{int}=3$ ab$^{-1}$ are found to be thirteen orders of magnitude stronger than the upper bound obtained from rare decay $Z\to\gamma\gamma\nu\bar{\nu}$ analysis using LEP data.","Thu, 24 Aug 2023 19:27:20 UTC (141 KB)"
"137","Short Run Transit Route Planning Decision Support System Using a Deep Learning-Based Weighted Graph","Nadav Shalit, Michael Fire, Dima Kagan, Eran Ben-Elia","Artificial Intelligence (cs.AI)","Public transport routing plays a crucial role in transit network design, ensuring a satisfactory level of service for passengers. However, current routing solutions rely on traditional operational research heuristics, which can be time-consuming to implement and lack the ability to provide quick solutions. Here, we propose a novel deep learning-based methodology for a decision support system that enables public transport (PT) planners to identify short-term route improvements rapidly. By seamlessly adjusting specific sections of routes between two stops during specific times of the day, our method effectively reduces times and enhances PT services. Leveraging diverse data sources such as GTFS and smart card data, we extract features and model the transportation network as a directed graph. Using self-supervision, we train a deep learning model for predicting lateness values for road segments. These lateness values are then utilized as edge weights in the transportation graph, enabling efficient path searching. Through evaluating the method on Tel Aviv, we are able to reduce times on more than 9\% of the routes. The improved routes included both intraurban and suburban routes showcasing a fact highlighting the model's versatility. The findings emphasize the potential of our data-driven decision support system to enhance public transport and city logistics, promoting greater efficiency and reliability in PT services.","Thu, 24 Aug 2023 14:37:55 UTC (1,609 KB)"
"138","CXL Memory as Persistent Memory for Disaggregated HPC: A Practical Approach","Yehonatan Fridman, Suprasad Mutalik Desai, Navneet Singh, Thomas Willhalm, Gal Oren","Distributed, Parallel, and Cluster Computing (cs.DC)","In the landscape of High-Performance Computing (HPC), the quest for efficient and scalable memory solutions remains paramount. The advent of Compute Express Link (CXL) introduces a promising avenue with its potential to function as a Persistent Memory (PMem) solution in the context of disaggregated HPC systems. This paper presents a comprehensive exploration of CXL memory's viability as a candidate for PMem, supported by physical experiments conducted on cutting-edge multi-NUMA nodes equipped with CXL-attached memory prototypes. Our study not only benchmarks the performance of CXL memory but also illustrates the seamless transition from traditional PMem programming models to CXL, reinforcing its practicality. To substantiate our claims, we establish a tangible CXL prototype using an FPGA card embodying CXL 1.1/2.0 compliant endpoint designs (Intel FPGA CXL IP). Performance evaluations, executed through the STREAM and STREAM-PMem benchmarks, showcase CXL memory's ability to mirror PMem characteristics in App-Direct and Memory Mode while achieving impressive bandwidth metrics with Intel 4th generation Xeon (Sapphire Rapids) processors. The results elucidate the feasibility of CXL memory as a persistent memory solution, outperforming previously established benchmarks. In contrast to published DCPMM results, our CXL-DDR4 memory module offers comparable bandwidth to local DDR4 memory configurations, albeit with a moderate decrease in performance. The modified STREAM-PMem application underscores the ease of transitioning programming models from PMem to CXL, thus underscoring the practicality of adopting CXL memory.","Mon, 21 Aug 2023 13:27:27 UTC (4,550 KB)"
"139","To Healthier Ethereum: A Comprehensive and Iterative Smart Contract Weakness Enumeration","Jiachi Chen, Mingyuan Huang, Zewei Lin, Peilin Zheng, Zibin Zheng","Software Engineering (cs.SE)","With the increasing popularity of cryptocurrencies and blockchain technology, smart contracts have become a prominent feature in developing decentralized applications. However, these smart contracts are susceptible to vulnerabilities that hackers can exploit, resulting in significant financial losses. In response to this growing concern, various initiatives have emerged. Notably, the SWC vulnerability list played an important role in raising awareness and understanding of smart contract weaknesses. However, the SWC list lacks maintenance and has not been updated with new vulnerabilities since 2020. To address this gap, this paper introduces the Smart Contract Weakness Enumeration (SWE), a comprehensive and practical vulnerability list up until 2023. We collect 273 vulnerability descriptions from 86 top conference papers and journal papers, employing open card sorting techniques to deduplicate and categorize these descriptions. This process results in the identification of 40 common contract weaknesses, which are further classified into 20 sub-research fields through thorough discussion and analysis. SWE provides a systematic and comprehensive list of smart contract vulnerabilities, covering existing and emerging vulnerabilities in the last few years. Moreover, SWE is a scalable, continuously iterative program. We propose two update mechanisms for the maintenance of SWE. Regular updates involve the inclusion of new vulnerabilities from future top papers, while irregular updates enable individuals to report new weaknesses for review and potential addition to SWE.","Sun, 20 Aug 2023 10:46:39 UTC (1,144 KB)"
"140","A tailored Handwritten-Text-Recognition System for Medieval Latin","Philipp Koch, Gilary Vera Nuñez, Esteban Garces Arias, Christian Heumann, Matthias Schöffel, Alexander Häberlin, Matthias Aßenmacher","Computer Vision and Pattern Recognition (cs.CV)","The Bavarian Academy of Sciences and Humanities aims to digitize its Medieval Latin Dictionary. This dictionary entails record cards referring to lemmas in medieval Latin, a low-resource language. A crucial step of the digitization process is the Handwritten Text Recognition (HTR) of the handwritten lemmas found on these record cards. In our work, we introduce an end-to-end pipeline, tailored to the medieval Latin dictionary, for locating, extracting, and transcribing the lemmas. We employ two state-of-the-art (SOTA) image segmentation models to prepare the initial data set for the HTR task. Furthermore, we experiment with different transformer-based models and conduct a set of experiments to explore the capabilities of different combinations of vision encoders with a GPT-2 decoder. Additionally, we also apply extensive data augmentation resulting in a highly competitive model. The best-performing setup achieved a Character Error Rate (CER) of 0.015, which is even superior to the commercial Google Cloud Vision model, and shows more stable performance.","Fri, 18 Aug 2023 08:02:52 UTC (3,249 KB)"
"141","Cutoff in the Bernoulli-Laplace Model With Unequal Colors and Urn Sizes","Thomas Griffin, Bailey Hall, Jackson Hebner, David Herzog, Denis Selyuzhitsky, Kevin Wong, John Wright","Probability (math.PR)","We consider a generalization of the Bernoulli-Laplace model in which there are two urns and $n$ total balls, of which $r$ are red and $n - r$ white, and where the left urn holds $m$ balls. At each time increment, $k$ balls are chosen uniformly at random from each urn and then swapped. This system can be used to model phenomena such as gas particle interchange between containers or card shuffling. Under a reasonable set of assumptions, we bound the mixing time of the resulting Markov chain asymptotically in $n$ with cutoff at $\log{n}$ and constant window. Among other techniques, we employ the spectral analysis of arXiv:0906.4242 on the Markov transition kernel and the chain coupling tools of arXiv:2203.08647 and arXiv:1606.01437.","Wed, 16 Aug 2023 21:19:51 UTC (113 KB)"
"142","Quad Squares","Nikhil Byrapuram, Hwiseo (Irene)Choi, Adam Ge, Selena Ge, Tanya Khovanova, Sylvia Zia Lee, Evin Liang, Rajarshi Mandal, Aika Oki, Daniel Wu, Michael Yang","History and Overview (math.HO)","We study 4-by-4 squares formed by cards from the EvenQuads deck. EvenQuads is a card game with 64 cards where cards have 3 attributes with 4 values in each attribute. A quad is four cards with all attributes the same, all different, or half and half. We define Latin quad squares as squares where the cards in each row and column have different values for each attribute. We define semimagic quad squares as squares where each row and column form a quad. For magic quad squares, we add a requirement that the diagonals have to form a quad. We also define strongly magic quad squares. We analyze types of semimagic and strongly magic quad squares. We also calculate the number of semimagic, magic, and strongly magic quad squares for quad decks of any size. These squares can be described in terms of integers. Four integers form a quad when their bitwise XOR is zero.","Mon, 14 Aug 2023 20:49:36 UTC (18 KB)"
"143","Variations on the Reinforcement Learning performance of Blackjack","Avish Buramdoyal, Tim Gebbie","Artificial Intelligence (cs.AI)","Blackjack or ""21"" is a popular card-based game of chance and skill. The objective of the game is to win by obtaining a hand total higher than the dealer's without exceeding 21. The ideal blackjack strategy will maximize financial return in the long run while avoiding gambler's ruin. The stochastic environment and inherent reward structure of blackjack presents an appealing problem to better understand reinforcement learning agents in the presence of environment variations. Here we consider a q-learning solution for optimal play and investigate the rate of learning convergence of the algorithm as a function of deck size. A blackjack simulator allowing for universal blackjack rules is also implemented to demonstrate the extent to which a card counter perfectly using the basic strategy and hi-lo system can bring the house to bankruptcy and how environment variations impact this outcome. The novelty of our work is to place this conceptual understanding of the impact of deck size in the context of learning agent convergence.","Wed, 9 Aug 2023 13:38:00 UTC (809 KB)"
"144","Follow Anything: Open-set detection, tracking, and following in real-time","Alaa Maalouf, Ninad Jadhav, Krishna Murthy Jatavallabhula, Makram Chahine, Daniel M.Vogt, Robert J. Wood, Antonio Torralba, Daniela Rus","Robotics (cs.RO)","Tracking and following objects of interest is critical to several robotics use cases, ranging from industrial automation to logistics and warehousing, to healthcare and security. In this paper, we present a robotic system to detect, track, and follow any object in real-time. Our approach, dubbed ``follow anything'' (FAn), is an open-vocabulary and multimodal model -- it is not restricted to concepts seen at training time and can be applied to novel classes at inference time using text, images, or click queries. Leveraging rich visual descriptors from large-scale pre-trained models (foundation models), FAn can detect and segment objects by matching multimodal queries (text, images, clicks) against an input image sequence. These detected and segmented objects are tracked across image frames, all while accounting for occlusion and object re-emergence. We demonstrate FAn on a real-world robotic system (a micro aerial vehicle) and report its ability to seamlessly follow the objects of interest in a real-time control loop. FAn can be deployed on a laptop with a lightweight (6-8 GB) graphics card, achieving a throughput of 6-20 frames per second. To enable rapid adoption, deployment, and extensibility, we open-source all our code on our project webpage at this https URL . We also encourage the reader to watch our 5-minutes explainer video in this this https URL .","Thu, 10 Aug 2023 17:57:06 UTC (44,258 KB)[v2] Sat, 10 Feb 2024 03:53:18 UTC (41,447 KB)"
"145","Assessment of POS Owners Awareness of Cybersecurity and Insider Threats in POS Kiosks Related Financial Crimes","Rawlings Fiberesima","Cryptography and Security (cs.CR)","The introduction of point of sales POS technologies as a payment system was welcoming and constitutes one of the major breakthroughs in the efforts made to rejuvenate the global financial systems. However, like other information technology IT based financial systems, the POS also poses some cybersecurity security threats. The unique thing about the POS is that the main cybersecurity threats it poses to most users are not IT based which refers to unauthorized access and gaining information without the knowledge of the user. The threats are rather connected to the mode of operation of POS kiosks, particularly as experienced in most parts of Nigeria. The mode of operation exposes users cards to possible cloning.","Tue, 1 Aug 2023 18:43:59 UTC (1,010 KB)"
"146","The odd Hummer principle","Sergio Fernandez de soto Guerrero","History and Overview (math.HO)","The Hummer Principle was born from the mind of Bob Hummer in 1946, which consists of performing card shuffles with an even number of cards while leaving some properties of the deck intact. In this document, we will present a generalization of this principle for an odd number of cards, along with ideas for applying and adapting magic tricks that use the Hummer Principle to a more general setting. Finally, we will discuss future work in this area.","Thu, 3 Aug 2023 17:45:32 UTC (10 KB)[v2] Wed, 13 Dec 2023 16:43:18 UTC (10 KB)"
"147","IoT Based Smart Attendance System Using Rfid: A Systematic Literature Review","Kashif Ishaq, Samra Bibi","Other Computer Science (cs.OH)","The use of Radio Frequency Identification (RFID) technology is ubiquitous in a number of businesses and sectors, including retail sales, smart cities, agriculture, and transportation. Additionally, educational institutions have started using RFID to track student attendance, combining this technology with Google Sheets and the Internet of Things (IoT) to build a real-time attendance tracking system. For a thorough examination of the creation of a student attendance system, this paper includes a systematic literature evaluation of 21 major research published on IoT based attendance systems employing RFID. This RFID-based attendance system enables automation, eliminating several problems connected with the manual process, such as time wasting, proxies, and the possibility of losing the attendance sheet, in contrast to the traditional attendance system, which depends on manual signatures. By creating a system that automatically registers students' attendance by merely flashing their student cards at the RFID reader, all the aforementioned difficulties may be successfully addressed. This automated method guarantees attendance monitoring accuracy and dependability while also saving time. This paper's conclusion highlights the significant advantages of implementing an IoT-based attendance system based on RFID technology. The suggested solution provides a trustworthy, efficient, and secure alternative to manual attendance techniques, successfully addressing their shortcomings. This paper offers helpful insights for institutions looking to create a cutting-edge attendance system that increases student involvement and academic achievement by looking at guiding principles, best practices, and the successful resolution of difficulties.","Thu, 3 Aug 2023 19:03:09 UTC (941 KB)"
"148","Analyzing the Reporting Error of Public Transport Trips in the Danish National Travel Survey Using Smart Card Data","Georges Sfeir, Filipe Rodrigues, Maya Abou Zeid, Francisco Camara Pereira","Applications (stat.AP)","Household travel surveys have been used for decades to collect individuals and households' travel behavior. However, self-reported surveys are subject to recall bias, as respondents might struggle to recall and report their activities accurately. This study examines the time reporting error of public transit users in a nationwide household travel survey by matching, at the individual level, five consecutive years of data from two sources, namely the Danish National Travel Survey (TU) and the Danish Smart Card system (Rejsekort). Survey respondents are matched with travel cards from the Rejsekort data solely based on the respondents' declared spatiotemporal travel behavior. Approximately, 70% of the respondents were successfully matched with Rejsekort travel cards. The findings reveal a median time reporting error of 11.34 minutes, with an Interquartile Range of 28.14 minutes. Furthermore, a statistical analysis was performed to explore the relationships between the survey respondents' reporting error and their socio-economic and demographic characteristics. The results indicate that females and respondents with a fixed schedule are in general more accurate than males and respondents with a flexible schedule in reporting their times of travel. Moreover, trips reported during weekdays or via the internet displayed higher accuracies compared to trips reported during weekends and holidays or via telephones. This disaggregated analysis provides valuable insights that could help in improving the design and analysis of travel surveys, as well accounting for reporting errors/biases in travel survey-based applications. Furthermore, it offers valuable insights underlying the psychology of travel recall by survey respondents.","Wed, 2 Aug 2023 15:07:25 UTC (1,362 KB)[v2] Tue, 12 Sep 2023 11:09:52 UTC (472 KB)"
"149","Maximizing Success Rate of Payment Routing using Non-stationary Bandits","Aayush Chaudhary, Abhinav Rai, Abhishek Gupta","Machine Learning (cs.LG)","This paper discusses the system architecture design and deployment of non-stationary multi-armed bandit approaches to determine a near-optimal payment routing policy based on the recent history of transactions. We propose a Routing Service architecture using a novel Ray-based implementation for optimally scaling bandit-based payment routing to over 10,000 transactions per second, adhering to the system design requirements and ecosystem constraints with Payment Card Industry Data Security Standard (PCI DSS). We first evaluate the effectiveness of multiple bandit-based payment routing algorithms on a custom simulator to benchmark multiple non-stationary bandit approaches and identify the best hyperparameters. We then conducted live experiments on the payment transaction system on a fantasy sports platform Dream11. In the live experiments, we demonstrated that our non-stationary bandit-based algorithm consistently improves the success rate of transactions by 0.92% compared to the traditional rule-based methods over one month.","Wed, 2 Aug 2023 09:23:16 UTC (3,492 KB)[v2] Fri, 6 Oct 2023 07:53:37 UTC (3,492 KB)"
"150","Confidence-Building Measures for Artificial Intelligence: Workshop Proceedings","Sarah Shoker, Andrew Reddie, Sarah Barrington, Ruby Booth, Miles Brundage, Husanjot Chahal, Michael Depp, Bill Drexel, Ritwik Gupta, Marina Favaro, Jake Hecla, Alan Hickey, Margarita Konaev, Kirthi Kumar, Nathan Lambert, Andrew Lohn, Cullen O'Keefe, Nazneen Rajani, Michael Sellitto, Robert Trager, Leah Walker, Alexa Wehsener, Jessica Young","Computers and Society (cs.CY)","Foundation models could eventually introduce several pathways for undermining state security: accidents, inadvertent escalation, unintentional conflict, the proliferation of weapons, and the interference with human diplomacy are just a few on a long list. The Confidence-Building Measures for Artificial Intelligence workshop hosted by the Geopolitics Team at OpenAI and the Berkeley Risk and Security Lab at the University of California brought together a multistakeholder group to think through the tools and strategies to mitigate the potential risks introduced by foundation models to international security. Originating in the Cold War, confidence-building measures (CBMs) are actions that reduce hostility, prevent conflict escalation, and improve trust between parties. The flexibility of CBMs make them a key instrument for navigating the rapid changes in the foundation model landscape. Participants identified the following CBMs that directly apply to foundation models and which are further explained in this conference proceedings: 1. crisis hotlines 2. incident sharing 3. model, transparency, and system cards 4. content provenance and watermarks 5. collaborative red teaming and table-top exercises and 6. dataset and evaluation sharing. Because most foundation model developers are non-government entities, many CBMs will need to involve a wider stakeholder community. These measures can be implemented either by AI labs or by relevant government actors.","Tue, 1 Aug 2023 22:20:11 UTC (114 KB)[v2] Thu, 3 Aug 2023 20:06:39 UTC (114 KB)"
